# RAGç³»ç»Ÿæµ‹è¯•

## RAGç³»ç»Ÿç®€è¿°

ä½¿ç”¨Qwen3-8B+Langchain+BGE-M3 æ­å»ºæœ¬åœ° RAG ç³»ç»Ÿ
mysqlæ­å»ºæ•°æ®åº“

å½“å‰ä¸»æµå¤§æ¨¡å‹ï¼ˆå¦‚GPT-4ã€Codexã€PanGu-Coder2ã€Qwen3ç­‰ï¼‰åœ¨é€šç”¨ä»£ç ç”Ÿæˆä»»åŠ¡ä¸­å·²å±•ç°è¾ƒå¼ºèƒ½åŠ›ã€‚ç„¶è€Œï¼Œè¿™äº›æ¨¡å‹ä¸»è¦é¢å‘é€šç”¨ç¼–ç¨‹è¯­è¨€ï¼ˆå¦‚Pythonã€Javaï¼‰ï¼Œé’ˆå¯¹ä»¿çœŸè„šæœ¬è¿™ç±»é¢†åŸŸç‰¹å®šè¯­è¨€ï¼ˆDSLï¼‰çš„ç ”ç©¶ä»è¾ƒå°‘ã€‚åœ¨è‡ªåŠ¨åŒ–æµ‹è¯•é¢†åŸŸï¼Œå·²æœ‰ç±»ä¼¼æŠ€æœ¯åº”ç”¨ã€‚ä¾‹å¦‚ï¼Œé‚®å‚¨é“¶è¡Œé€šè¿‡å¤§æ¨¡å‹ç»“åˆçŸ¥è¯†åº“å’Œæç¤ºå·¥ç¨‹ï¼Œå®ç°äº†æ¥å£æµ‹è¯•è„šæœ¬çš„æ™ºèƒ½ç”Ÿæˆï¼Œæ”¯æŒä»è‡ªç„¶è¯­è¨€éœ€æ±‚åˆ°è„šæœ¬çš„è½¬æ¢ï¼Œå¹¶åˆ©ç”¨å¤–æŒ‚çŸ¥è¯†åº“æå‡ç”Ÿæˆå‡†ç¡®æ€§ã€‚è¿™è¡¨æ˜é¢†åŸŸé€‚é…çš„å¤§æ¨¡å‹åœ¨è„šæœ¬ç”Ÿæˆä¸­å…·æœ‰å¯è¡Œæ€§ã€‚

## æ•°æ®åº“ç»“æ„

ä¸€ä¸ªä¸­ç­‰è§„æ¨¡çš„ç”µå•†ä¸šåŠ¡æ•°æ®åº“ï¼ŒåŒ…å«7ä¸ªä¸»è¦è¡¨

```mermaid
erDiagram
    users ||--o{ orders : "1:N"
    users ||--o{ reviews : "1:N"
    categories ||--o{ products : "1:N"
    products ||--o{ order_items : "1:N"
    products ||--o{ reviews : "1:N"
    products ||--o{ inventory : "1:1"
    orders ||--o{ order_items : "1:N"
    orders ||--o{ reviews : "1:1"

    users {
        int user_id PK
        varchar username UK
        varchar email UK
        varchar phone
        varchar first_name
        varchar last_name
        int age
        enum gender
        varchar city
        varchar country
        date registration_date
        datetime last_login
        enum loyalty_level
        int total_orders
        decimal total_spent
        timestamp created_at
    }

    categories {
        int category_id PK
        varchar category_name
        int parent_category_id FK
        text description
        int level
        int product_count
        timestamp created_at
    }

    products {
        int product_id PK
        varchar product_name
        text description
        int category_id FK
        int subcategory_id
        varchar brand
        decimal price
        decimal cost_price
        int stock_quantity
        int min_stock_level
        decimal weight
        varchar dimensions
        varchar color
        varchar size
        boolean is_active
        decimal rating
        int review_count
        timestamp created_at
        timestamp updated_at
    }

    orders {
        int order_id PK
        int user_id FK
        datetime order_date
        enum status
        decimal total_amount
        decimal shipping_cost
        decimal tax_amount
        decimal discount_amount
        enum payment_method
        enum payment_status
        text shipping_address
        text billing_address
        varchar tracking_number
        date estimated_delivery
        date actual_delivery
        timestamp created_at
        timestamp updated_at
    }

    order_items {
        int order_item_id PK
        int order_id FK
        int product_id FK
        int quantity
        decimal unit_price
        decimal discount
        decimal line_total
        timestamp created_at
    }

    inventory {
        int inventory_id PK
        int product_id FK
        int warehouse_id
        int quantity
        int reserved_quantity
        int available_quantity
        date last_restock_date
        date next_restock_date
        timestamp created_at
    }

    reviews {
        int review_id PK
        int user_id FK
        int product_id FK
        int order_id FK
        int rating
        varchar title
        text comment
        boolean is_verified_purchase
        int helpful_votes
        timestamp created_at
    }
```

## æµ‹è¯•æ€è·¯è¯´æ˜

é€šè¿‡pyæ–‡ä»¶ç”Ÿæˆä¸Šè¿°sqlæ•°æ®åº“
é€šè¿‡Qwen3ä¸»åŠ¨å­¦ä¹ æ•°æ®åº“ï¼Œç”Ÿæˆæœ¬åœ°ragæ–‡ä»¶
é€šè¿‡RAGå’ŒGraph RAGæå‡æ•°æ®åº“æŸ¥è¯¢å‡†ç¡®æ€§ï¼š
è®¾ç«‹åç§æŸ¥è¯¢æƒ…å†µï¼Œç”±ç®€å•åˆ°å¤æ‚
å¯¹æ¯ç§æƒ…å†µåˆ†æ— ragï¼Œæœ‰ragä¸¤ç§æƒ…å†µï¼Œç”ŸæˆæŸ¥è¯¢è¯­å¥
æŠŠç”Ÿæˆçš„æŸ¥è¯¢è¯­å¥é€šè¿‡pythonè„šæœ¬éªŒè¯æŸ¥è¯¢ï¼Œä¸æ ‡å‡†ç»“æœè¿›è¡Œå¯¹æ¯”ï¼Œè®¡ç®—å‡†ç¡®ç‡

## æµ‹è¯•åˆ—è¡¨

```
			{
                "name": "åœºæ™¯1: ç®€å•å•è¡¨æŸ¥è¯¢",
                "question": "æŸ¥è¯¢å‰10ä¸ªç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT user_id, username, email, city, country FROM users LIMIT 10"
            },
            {
                "name": "åœºæ™¯2: å¸¦æ¡ä»¶çš„å•è¡¨æŸ¥è¯¢", 
                "question": "æŸ¥è¯¢æ¥è‡ªçº½çº¦çš„ç”¨æˆ·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT * FROM users WHERE city = 'New York' LIMIT 10"
            },
            {
                "name": "åœºæ™¯3: ä¸¤è¡¨è¿æ¥æŸ¥è¯¢",
                "question": "æŸ¥è¯¢äº§å“åŠå…¶åˆ†ç±»ä¿¡æ¯ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT p.product_name, p.price, c.category_name FROM products p JOIN categories c ON p.category_id = c.category_id LIMIT 10"
            },
            {
                "name": "åœºæ™¯4: èšåˆæŸ¥è¯¢",
                "question": "ç»Ÿè®¡æ¯ä¸ªåŸå¸‚çš„ç”¨æˆ·æ•°é‡ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT city, COUNT(*) as user_count FROM users GROUP BY city ORDER BY user_count DESC LIMIT 10"
            },
            {
                "name": "åœºæ™¯5: å¤æ‚å¤šè¡¨è¿æ¥",
                "question": "æŸ¥è¯¢æ¯ä¸ªç”¨æˆ·çš„è®¢å•æ€»é‡‘é¢ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT u.username, SUM(o.total_amount) as total_spent FROM users u JOIN orders o ON u.user_id = o.user_id GROUP BY u.user_id, u.username ORDER BY total_spent DESC LIMIT 10"
            },
            # æ›´å…·æŒ‘æˆ˜æ€§çš„åœºæ™¯
            {
                "name": "åœºæ™¯6: å¤æ‚åˆ—åæŸ¥è¯¢",
                "question": "æŸ¥è¯¢ç”¨æˆ·çš„æ³¨å†Œæ—¥æœŸå’Œæœ€åç™»å½•æ—¶é—´ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€ç”¨æˆ·åå’ŒåŸå¸‚ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT user_id, username, city, registration_date, last_login FROM users LIMIT 10",
                "challenge": "éœ€è¦çŸ¥é“å…·ä½“çš„æ—¥æœŸæ—¶é—´åˆ—å"
            },
            {
                "name": "åœºæ™¯7: å¤šè¡¨è¿æ¥ä¸ç‰¹å®šåˆ—", 
                "question": "æŸ¥è¯¢è®¢å•è¯¦æƒ…ï¼ŒåŒ…æ‹¬è®¢å•IDã€ç”¨æˆ·åã€äº§å“åç§°ã€æ•°é‡å’Œå•ä»·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT o.order_id, u.username, p.product_name, oi.quantity, oi.unit_price 
FROM orders o 
JOIN users u ON o.user_id = u.user_id 
JOIN order_items oi ON o.order_id = oi.order_id 
JOIN products p ON oi.product_id = p.product_id 
LIMIT 10""",
                "challenge": "éœ€è¦çŸ¥é“å››è¡¨è¿æ¥å’Œæ­£ç¡®çš„åˆ—å"
            },
            {
                "name": "åœºæ™¯8: èšåˆå‡½æ•°ä¸åˆ†ç»„",
                "question": "ç»Ÿè®¡æ¯ä¸ªäº§å“ç±»åˆ«çš„å¹³å‡ä»·æ ¼å’Œäº§å“æ•°é‡ï¼ŒæŒ‰å¹³å‡ä»·æ ¼é™åºæ’åˆ—ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT c.category_name, 
AVG(p.price) as avg_price, 
COUNT(p.product_id) as product_count 
FROM products p 
JOIN categories c ON p.category_id = c.category_id 
GROUP BY c.category_id, c.category_name 
ORDER BY avg_price DESC""",
                "challenge": "éœ€è¦çŸ¥é“èšåˆå‡½æ•°å’Œåˆ†ç»„é€»è¾‘"
            },
            {
                "name": "åœºæ™¯9: å¤æ‚æ¡ä»¶æŸ¥è¯¢",
                "question": "æŸ¥è¯¢æœ€è¿‘30å¤©å†…æ³¨å†Œä¸”æ¥è‡ªç¾å›½çº½çº¦çš„é»„é‡‘ç­‰çº§ç”¨æˆ·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT user_id, username, email, city, loyalty_level, registration_date 
FROM users 
WHERE city = 'New York' 
AND country = 'USA' 
AND loyalty_level = 'Gold' 
AND registration_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)""",
                "challenge": "éœ€è¦çŸ¥é“æ—¥æœŸå‡½æ•°å’Œå¤šä¸ªæ¡ä»¶"
            },
            {
                "name": "åœºæ™¯10: å­æŸ¥è¯¢ä¸é«˜çº§åˆ†æ",
                "question": "æŸ¥è¯¢æ¶ˆè´¹é‡‘é¢é«˜äºå¹³å‡æ¶ˆè´¹æ°´å¹³çš„ç”¨æˆ·åŠå…¶è®¢å•æ€»æ•°ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT u.username, 
COUNT(o.order_id) as order_count, 
SUM(o.total_amount) as total_spent 
FROM users u 
JOIN orders o ON u.user_id = o.user_id 
GROUP BY u.user_id, u.username 
HAVING total_spent > (SELECT AVG(total_amount) FROM orders) 
ORDER BY total_spent DESC 
LIMIT 10""",
                "challenge": "éœ€è¦å­æŸ¥è¯¢å’ŒHAVINGå­å¥"
            }
```





## è¾“å‡ºï¼š

````
(HJZconda) PS D:\HuangJZh\qwen3\rag_system> python database_rag_system.py
ğŸš€ å¼€å§‹RAGå¯¹æ¯”æµ‹è¯•
============================================================
ğŸ“ ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ•°æ®åº“æ–‡æ¡£...
âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ
âœ… æ•°æ®åº“æ–‡æ¡£å·²ç”Ÿæˆåˆ° D:/HuangJZh/Qwen3/enhanced_database_docs

ğŸ”§ ç¬¬äºŒæ­¥ï¼šæ„å»ºRAGç³»ç»Ÿ...
åŠ è½½BGE-M3åµŒå…¥æ¨¡å‹...
åŠ è½½Qwen3æ¨¡å‹: D:/HuangJZh/Qwen/Qwen3-8B
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:12<00:00,  2.60s/it]
Device set to use cuda
åŠ è½½å·²æœ‰å‘é‡åº“...

ğŸ¯ ç¬¬ä¸‰æ­¥ï¼šè¿è¡ŒæŒ‘æˆ˜æ€§æµ‹è¯•åœºæ™¯...
âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ

================================================================================
æµ‹è¯•: åœºæ™¯1: ç®€å•å•è¡¨æŸ¥è¯¢
é—®é¢˜: æŸ¥è¯¢å‰10ä¸ªç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT user_id, username, email
FROM users
ORDER BY user_id
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT username, email, registration_date
FROM users
ORDER BY user_id ASC
LIMIT 10

================================================================================
æµ‹è¯•: åœºæ™¯2: å¸¦æ¡ä»¶çš„å•è¡¨æŸ¥è¯¢
é—®é¢˜: æŸ¥è¯¢æ¥è‡ªçº½çº¦çš„ç”¨æˆ·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT * FROM users WHERE address LIKE '%çº½çº¦%' LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT * FROM users WHERE city = 'New York' LIMIT 10

================================================================================
æµ‹è¯•: åœºæ™¯3: ä¸¤è¡¨è¿æ¥æŸ¥è¯¢
é—®é¢˜: æŸ¥è¯¢äº§å“åŠå…¶åˆ†ç±»ä¿¡æ¯ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECTè¯­å¥é€‰æ‹©æ‰€éœ€çš„åˆ—ï¼Œå¹¶ä½¿ç”¨LIMITå­å¥æ¥é™åˆ¶è¾“å‡ºæ•°é‡ä¸º10æ¡ã€‚

ä»¥ä¸‹æ˜¯å®ç°è¯¥éœ€æ±‚çš„SQLæŸ¥è¯¢è¯­å¥ï¼š

SELECT p.*, c.*
FROM products p
JOIN categories c ON p.category_id = c.id
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT p.*, c.category_name, c.parent_category_id, c.level
FROM products p
JOIN categories c ON p.category_id = c.category_id
LIMIT 10

================================================================================
æµ‹è¯•: åœºæ™¯4: èšåˆæŸ¥è¯¢
é—®é¢˜: ç»Ÿè®¡æ¯ä¸ªåŸå¸‚çš„ç”¨æˆ·æ•°é‡ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT city, COUNT(*) AS user_count
FROM users
GROUP BY city
ORDER BY user_count DESC
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT city, COUNT(*) AS user_count
FROM users
GROUP BY city
ORDER BY user_count DESC
LIMIT 10

================================================================================
æµ‹è¯•: åœºæ™¯5: å¤æ‚å¤šè¡¨è¿æ¥
é—®é¢˜: æŸ¥è¯¢æ¯ä¸ªç”¨æˆ·çš„è®¢å•æ€»é‡‘é¢ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT
    o.user_id,
    SUM(oi.price) AS total_amount
FROM
    orders o
JOIN
    order_items oi ON o.order_id = oi.order_id
WHERE
    o.status = 'completed'
GROUP BY
    o.user_id
ORDER BY
    total_amount DESC
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT u.username, SUM(o.total_amount) AS total_spent
FROM users u
JOIN orders o ON u.user_id = o.user_id
GROUP BY u.user_id, u.username
ORDER BY total_spent DESC
LIMIT 10

================================================================================
æµ‹è¯•: åœºæ™¯6: å¤æ‚åˆ—åæŸ¥è¯¢
é—®é¢˜: æŸ¥è¯¢ç”¨æˆ·çš„æ³¨å†Œæ—¥æœŸå’Œæœ€åç™»å½•æ—¶é—´ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€ç”¨æˆ·åå’ŒåŸå¸‚ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...
You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT user_id, username, registration_date, last_login, city FROM users LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT user_id, username, city, registration_date, last_login_time
FROM users
LIMIT 10

================================================================================
æµ‹è¯•: åœºæ™¯7: å¤šè¡¨è¿æ¥ä¸ç‰¹å®šåˆ—
é—®é¢˜: æŸ¥è¯¢è®¢å•è¯¦æƒ…ï¼ŒåŒ…æ‹¬è®¢å•IDã€ç”¨æˆ·åã€äº§å“åç§°ã€æ•°é‡å’Œå•ä»·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT
    o.order_id,
    u.username,
    p.product_name,
    oi.quantity,
    oi.unit_price
FROM
    orders o
JOIN
    users u ON o.user_id = u.user_id
JOIN
    order_items oi ON o.order_id = oi.order_id
JOIN
    products p ON oi.product_id = p.product_id
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT o.order_id, u.username, p.product_name, oi.quantity, oi.unit_price
FROM orders o
JOIN users u ON o.user_id = u.user_id
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id
LIMIT 10
```

è¯¥æŸ¥è¯¢ï¼š
1. ä»`orders`è¡¨ä¸­é€‰æ‹©è®¢å•ä¿¡æ¯
2. é€šè¿‡`user_id`å­—æ®µä¸`users`è¡¨è¿›è¡ŒJOINæ“ä½œï¼Œè·å–ç”¨æˆ·å
3. é€šè¿‡`order_id`å­—æ®µä¸`order_items`è¡¨è¿›è¡ŒJOINæ“ä½œï¼Œè·å–è®¢å•é¡¹ä¿¡æ¯
4. é€šè¿‡`product_id`å­—æ®µä¸`products`è¡¨è¿›è¡ŒJOINæ“ä½œï¼Œè·å–äº§å“åç§°
5. æœ€ç»ˆåªè¿”å›å‰10æ¡è®°å½•

æ³¨æ„ï¼šè™½ç„¶æ‚¨æä¾›äº†æ•°æ®ç¤ºä¾‹ï¼Œä½†å®é™…æŸ¥è¯¢ä¸­å¹¶æœªä½¿ç”¨åˆ°è¿™äº›ç¤ºä¾‹æ•°æ®ï¼Œå› ä¸ºé—®é¢˜ä»…è¦æ±‚æŸ¥è¯¢è®¢å•è¯¦æƒ…ï¼Œè€Œä¸æ˜¯ç‰¹å®šäº§å“çš„è®¢å•ä¿¡æ¯ã€‚å¦‚æœéœ€è¦æ ¹æ®ç¤ºä¾‹æ•°æ®è¿›è¡Œè¿‡æ»¤ï¼Œå¯ä»¥æ·»åŠ ç›¸åº”çš„WHEREæ¡ä»¶ã€‚ 
ä¸è¿‡æ ¹æ®å½“å‰çš„é—®é¢˜æè¿°ï¼Œä¸éœ€è¦æ·»åŠ é¢å¤–çš„è¿‡æ»¤æ¡ä»¶ã€‚æ ¹æ®ç”¨æˆ·é—®é¢˜ä¸­çš„æè¿°ï¼Œæˆ‘éœ€è¦ç”Ÿæˆä¸€ä¸ªSQLæŸ¥è¯¢æ¥æ»¡è¶³ä»–ä»¬çš„éœ€æ±‚ã€‚ç”¨æˆ·æƒ³è¦æŸ¥è¯¢è®¢å•è¯¦æƒ…ï¼ŒåŒ…æ‹¬è®¢å•IDã€ç”¨æˆ·åã€äº§å“åç§°ã€æ•°é‡å’Œå•ä»· 
ï¼Œå¹¶ä¸”è¦é™åˆ¶è¾“å‡ºä¸º10ä¸ªç»“æœã€‚

é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®å®šæ¶‰åŠçš„è¡¨ã€‚æ ¹æ®é—®é¢˜æè¿°ï¼Œè¿™æ¶‰åŠåˆ°`orders`ã€`users`ã€`order_items`å’Œ`products`å››ä¸ªè¡¨ã€‚è¿™æ˜¯å› ä¸ºè®¢å•ä¿¡æ¯å­˜å‚¨åœ¨`orders`è¡¨ä¸­ï¼Œç”¨æˆ·ä¿¡æ¯å­˜å‚¨åœ¨`users`è¡¨ä¸­ï¼Œè®¢å•é¡¹ä¿¡æ¯ 
å­˜å‚¨åœ¨`order_items`è¡¨ä¸­ï¼Œè€Œäº§å“ä¿¡æ¯å­˜å‚¨åœ¨`products`è¡¨ä¸­ã€‚

æ¥ä¸‹æ¥ï¼Œæˆ‘éœ€è¦ç¡®å®šå¦‚ä½•å°†è¿™äº›è¡¨è¿æ¥èµ·æ¥ã€‚`orders`è¡¨é€šè¿‡`user_id`å­—æ®µä¸`users`è¡¨è¿æ¥ï¼Œä»¥è·å–ç”¨æˆ·åã€‚`orders`è¡¨é€šè¿‡`order_id`å­—æ®µä¸`order_items`è¡¨è¿æ¥ï¼Œä»¥è·å–è®¢å•é¡¹çš„ä¿¡æ¯ã€‚`order_items`è¡¨é€šè¿‡`product_id`å­—æ®µä¸`products`è¡¨è¿æ¥ï¼Œä»¥è·å–äº§å“åç§°ã€‚

ç„¶åï¼Œæˆ‘éœ€è¦é€‰æ‹©æ‰€éœ€çš„åˆ—ï¼š`order_id`æ¥è‡ª`orders`è¡¨ï¼Œ`username`æ¥è‡ª`users`è¡¨ï¼Œ`product_name`æ¥è‡ª`products`è¡¨ï¼Œ`quantity`å’Œ`unit_price`æ¥è‡ª`order_items`è¡¨ã€‚

æœ€åï¼Œä¸ºäº†é™åˆ¶è¾“å‡ºç»“æœä¸º10ä¸ªï¼Œæˆ‘éœ€è¦åœ¨æŸ¥è¯¢æœ«å°¾æ·»åŠ `LIMIT 10`å­å¥ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œæœ€ç»ˆçš„SQLæŸ¥è¯¢åº”è¯¥åŒ…æ‹¬å››ä¸ªè¡¨çš„JOINæ“ä½œï¼Œé€‰æ‹©æŒ‡å®šçš„åˆ—ï¼Œå¹¶åº”ç”¨LIMITå­å¥æ¥é™åˆ¶ç»“æœæ•°é‡ã€‚è¿™ä¸ªæŸ¥è¯¢åº”è¯¥èƒ½å¤Ÿæ­£ç¡®åœ°æ£€ç´¢å‡ºæ‰€éœ€çš„ä¿¡æ¯ï¼Œå¹¶ä¸”ç¬¦åˆç”¨æˆ·çš„è¦æ±‚ã€‚
### SQLæŸ¥è¯¢
```sql
SELECT o.order_id, u.username, p.product_name, oi.quantity, oi.unit_price
FROM orders o
JOIN users u ON o.user_id = u.user_id
JOIN order_items oi ON o.order_id = oi.order_id
JOIN products p ON oi.product_id = p.product_id
LIMIT 10
```æ ¹æ®ç”¨æˆ·é—®é¢˜ï¼Œæˆ‘ä»¬éœ€è¦æŸ¥è¯¢è®¢å•è¯¦æƒ…ï¼ŒåŒ…æ‹¬è®¢å•IDã€ç”¨æˆ·åã€äº§å“åç§°ã€æ•°é‡å’Œå•ä»·ï¼Œå¹¶ä¸”é™åˆ¶è¾“å‡ºä¸º10ä¸ªç»“æœã€‚è¿™ä¸ªæŸ¥è¯¢æ¶‰åŠå››ä¸ªè¡¨ï¼š`orders`ã€`users`ã€`order_items`å’Œ`products`ã€‚   

1. **è¡¨è¿æ¥**ï¼š
   - `orders`è¡¨é€šè¿‡`user_id`å­—æ®µä¸`users`è¡¨è¿æ¥ï¼Œä»¥è·å–ç”¨æˆ·åã€‚
   - `orders`è¡¨é€šè¿‡`order_id`å­—æ®µä¸`order_items`è¡¨è¿æ¥ï¼Œä»¥è·å–è®¢å•é¡¹ä¿¡æ¯ï¼ˆæ•°é‡å’Œå•ä»·ï¼‰ã€‚
   - `

================================================================================
æµ‹è¯•: åœºæ™¯8: èšåˆå‡½æ•°ä¸åˆ†ç»„
é—®é¢˜: ç»Ÿè®¡æ¯ä¸ªäº§å“ç±»åˆ«çš„å¹³å‡ä»·æ ¼å’Œäº§å“æ•°é‡ï¼ŒæŒ‰å¹³å‡ä»·æ ¼é™åºæ’åˆ—ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT
    c.name AS category_name,
    AVG(p.price) AS average_price,
    COUNT(*) AS product_count
FROM
    products p
JOIN
    categories c ON p.category_id = c.id
GROUP BY
    c.name
ORDER BY
    average_price DESC
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT c.category_name,
AVG(p.price) as avg_price,
COUNT(p.product_id) as product_count
FROM products p
JOIN categories c ON p.category_id = c.category_id
GROUP BY c.category_id, c.category_name
ORDER BY avg_price DESC
LIMIT 10
```

è¿™ä¸ªæŸ¥è¯¢ï¼š
1. ä»productsè¡¨å’Œcategoriesè¡¨è¿›è¡ŒJOINæ“ä½œï¼Œé€šè¿‡category_idå…³è”
2. ä½¿ç”¨AVG()è®¡ç®—æ¯ä¸ªç±»åˆ«çš„å¹³å‡ä»·æ ¼ï¼Œç”¨COUNT()ç»Ÿè®¡äº§å“æ•°é‡
3. æŒ‰ç…§category_idå’Œcategory_nameè¿›è¡Œåˆ†ç»„
4. æŒ‰avg_priceé™åºæ’åº
5. æœ€åä½¿ç”¨LIMIT 10é™åˆ¶è¾“å‡ºä¸ºå‰10æ¡è®°å½•

æ³¨æ„ï¼šè™½ç„¶åœ¨GROUP BYå­å¥ä¸­åŒæ—¶åŒ…å«äº†category_idå’Œcategory_nameï¼Œä½†å®é™…åº”ç”¨ä¸­å¦‚æœcategory_nameæ˜¯category_idçš„å”¯ä¸€æ ‡è¯†ï¼ˆå³æ¯ä¸ªcategory_idå¯¹åº”å”¯ä¸€çš„category_nameï¼‰ï¼Œåˆ™åªéœ€è¦GROUP BY category_idå³å¯ã€‚ä¸è¿‡ä¸ºäº†ä¿é™©èµ·è§ï¼Œè¿™é‡Œä¿ç•™äº†ä¸¤ä¸ªå­—æ®µçš„åˆ†ç»„ã€‚å¦‚æœæ•°æ®åº“ç³»ç»Ÿè¦æ±‚å¿…é¡»å°†æ‰€æœ‰éèšåˆåˆ—éƒ½åŒ…å«åœ¨GROUP BYå­å¥ä¸­ï¼Œåˆ™éœ€è¦ä¿ç•™è¿™ä¸¤ä¸ªå­—æ®µã€‚ä¸åŒæ•°æ®åº“ç³»ç»Ÿå¯¹æ­¤æœ‰ä¸åŒçš„
è¦æ±‚ï¼Œä¾‹å¦‚MySQLå…è®¸ä»…ä½¿ç”¨category_idåˆ†ç»„ï¼Œè€ŒPostgreSQLåˆ™éœ€è¦åŒæ—¶åŒ…å«ä¸¤ä¸ªå­—æ®µã€‚å› æ­¤ï¼Œè¯¥æŸ¥è¯¢åœ¨å¤§å¤šæ•°æ•°æ®åº“ç³»ç»Ÿä¸­éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚å¦‚æœçŸ¥é“å…·ä½“ä½¿ç”¨çš„æ•°æ®åº“ç±»å‹ï¼Œå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–è¿™ä¸ªæŸ¥
è¯¢ã€‚æ ¹æ®æ‚¨æä¾›çš„æ•°æ®ç¤ºä¾‹ï¼Œçœ‹èµ·æ¥category_idå’Œcategory_nameæ˜¯ç›¸å…³çš„ï¼Œæ‰€ä»¥å¯èƒ½åªéœ€è¦GROUP BY category_idå³å¯ã€‚ä¸è¿‡æŒ‰ç…§æ ‡å‡†SQLè§„èŒƒï¼Œæœ€å¥½è¿˜æ˜¯ä¿æŒGROUP BYä¸­çš„ä¸¤ä¸ªå­—æ®µã€‚å¦‚æœæ‚¨ç¡®å®šcategory_nameæ˜¯å”¯ä¸€çš„ï¼Œå¯ä»¥ç®€åŒ–ä¸ºGROUP BY c.category_idã€‚ä¸è¿‡æ ¹æ®åŸå§‹æä¾›çš„SQLæ¨¡å¼ï¼Œæˆ‘ä»¬ä¿æŒåŸæ ·ã€‚

è€ƒè™‘åˆ°æ‚¨ç»™å‡ºçš„æ•°æ®ç¤ºä¾‹æ˜¾ç¤ºcategory_idä¸ºæ•´æ•°ï¼Œè€Œcategory_nameä¸ºå­—ç¬¦ä¸²ï¼Œè¿™è¡¨æ˜å®ƒä»¬ä¹‹é—´å­˜åœ¨ä¸€å¯¹ä¸€çš„å…³ç³»ã€‚å› æ­¤ï¼Œæœ€ä¼˜åŒ–çš„å†™æ³•åº”è¯¥æ˜¯GROUP BY c.category_idã€‚ä½†æ˜¯ç”±äºåŸå§‹æä¾›çš„SQLæ¨¡ 
å¼ä¸­ä½¿ç”¨äº†GROUP BY c.category_id, c.category_nameï¼Œæ‰€ä»¥æˆ‘ä»¬ä¿æŒè¿™ç§å†™æ³•ä»¥ç¡®ä¿å…¼å®¹æ€§ã€‚å¦‚æœè¦ä¼˜åŒ–ï¼Œå¯ä»¥æ”¹ä¸ºGROUP BY c.category_idã€‚ä¸è¿‡æ ¹æ®åŸå§‹æä¾›çš„SQLæ¨¡å¼ï¼Œæˆ‘ä»¬ä¿æŒåŸæ ·ã€‚    

ç»¼ä¸Šæ‰€è¿°ï¼Œæœ€ç»ˆçš„SQLæŸ¥è¯¢å¦‚ä¸Šé¢æ‰€ç¤ºã€‚ è¿™ä¸ªæŸ¥è¯¢ç¬¦åˆæ‰€æœ‰ç»™å®šçš„è¦æ±‚ï¼Œå¹¶ä¸”åº”è¯¥èƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œã€‚ å¦‚æœæœ‰æ›´å¤šå…³äºæ•°æ®åº“ç³»ç»Ÿçš„å…·ä½“ä¿¡æ¯ï¼Œè¿˜å¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–è¿™ä¸ªæŸ¥è¯¢ã€‚

æœ€åï¼Œæˆ‘å†æ¬¡ç¡®è®¤è¿™ä¸ªæŸ¥è¯¢æ»¡è¶³æ‰€æœ‰è¦æ±‚ï¼š
- æ­£ç¡®ä½¿ç”¨äº†è¡¨åå’Œåˆ—å
- åŒ…å«äº†å¿…è¦çš„JOINæ¡ä»¶
- ä½¿ç”¨äº†æ­£ç¡®çš„GROUP BYå­å¥
- æ·»åŠ äº†ORDER BYè¿›è¡Œæ’åº
- ä½¿ç”¨LIMITé™åˆ¶è¾“å‡ºç»“æœä¸º10æ¡è®°å½•
- æ²¡æœ‰æ·»åŠ ä¸å¿…è¦çš„WHEREæ¡ä»¶
- ç¬¦åˆSQLè¯­æ³•è§„èŒƒ

å› æ­¤ï¼Œè¿™ä¸ªæŸ¥è¯¢åº”è¯¥èƒ½å¤Ÿæ­£ç¡®åœ°ç»Ÿè®¡æ•°æ®å¹¶è¿”å›æ‰€éœ€çš„ç»“æœã€‚

ç»è¿‡ä»”ç»†æ£€æŸ¥ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªæŸ¥è¯¢æ˜¯æ­£ç¡®çš„ã€‚å®ƒç¬¦åˆæ‰€æœ‰ç»™å®šçš„è¦æ±‚ï¼Œå¹¶ä¸”åº”è¯¥èƒ½å¤Ÿæ­£ç¡®æ‰§è¡Œã€‚å¦‚æœæœ‰ä»»ä½•ç‰¹å®šçš„æ•°æ®åº“ç³»ç»Ÿè¦æ±‚æˆ–çº¦æŸï¼Œå¯èƒ½éœ€è¦è¿›è¡Œè°ƒæ•´ï¼Œä½†åœ¨æ²¡æœ‰æ›´å¤šä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œè¿™ä¸ªæŸ¥è¯¢æ˜¯
æœ€ä½³é€‰æ‹©ã€‚

æœ€åï¼Œæˆ‘å†æ¬¡ç¡®è®¤è¿™ä¸ªæŸ¥è¯¢æ»¡è¶³æ‰€æœ‰è¦æ±‚ï¼š
- æ­£ç¡®ä½¿ç”¨äº†è¡¨åå’Œåˆ—å
- åŒ…å«äº†å¿…è¦çš„JOINæ¡ä»¶
- ä½¿ç”¨äº†æ­£ç¡®çš„GROUP BYå­å¥
- æ·»åŠ äº†ORDER BYè¿›è¡Œæ’åº
- ä½¿ç”¨LIMITé™åˆ¶è¾“å‡ºç»“æœä¸º10æ¡è®°å½•
- æ²¡æœ‰æ·»åŠ ä¸å¿…è¦çš„WHEREæ¡ä»¶
- ç¬¦åˆSQLè¯­æ³•è§„èŒƒ

å› æ­¤ï¼Œè¿™ä¸ªæŸ¥è¯¢åº”è¯¥èƒ½å¤Ÿæ­£ç¡®åœ°ç»Ÿè®¡æ•°æ®å¹¶è¿”å›æ‰€éœ€çš„ç»“æœã€‚

ç»è¿‡ä»”ç»†æ£€æŸ¥ï¼Œæˆ‘è®¤ä¸ºè¿™ä¸ªæŸ¥è¯¢

================================================================================
æµ‹è¯•: åœºæ™¯9: å¤æ‚æ¡ä»¶æŸ¥è¯¢
é—®é¢˜: æŸ¥è¯¢æœ€è¿‘30å¤©å†…æ³¨å†Œä¸”æ¥è‡ªç¾å›½çº½çº¦çš„é»„é‡‘ç­‰çº§ç”¨æˆ·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT *
FROM users
WHERE registration_date >= CURRENT_DATE - INTERVAL '30 days'
AND address = 'USA, New York'
AND user_level = 'Gold'
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT user_id, username, email, city, loyalty_level, registration_date 
FROM users
WHERE city = 'New York'
AND country = 'USA'
AND loyalty_level = 'Gold'
AND registration_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)
LIMIT 10

================================================================================
æµ‹è¯•: åœºæ™¯10: å­æŸ¥è¯¢ä¸é«˜çº§åˆ†æ
é—®é¢˜: æŸ¥è¯¢æ¶ˆè´¹é‡‘é¢é«˜äºå¹³å‡æ¶ˆè´¹æ°´å¹³çš„ç”¨æˆ·åŠå…¶è®¢å•æ€»æ•°ï¼Œé™åˆ¶10ä¸ªè¾“å‡º

1. æ— RAGç”ŸæˆSQL...

ğŸ” æ— RAGç»“æœ
ç”Ÿæˆçš„SQL:
 WITH user_spending AS (
    SELECT
        o.user_id,
        SUM(oi.price * oi.quantity) AS total_spent
    FROM
        orders o
    JOIN
        order_items oi ON o.order_id = oi.order_id
    GROUP BY
        o.user_id
),
average_spending AS (
    SELECT
        AVG(total_spent) AS avg_total
    FROM
        user_spending
)
SELECT
    us.user_id,
    COUNT(o.order_id) AS order_count
FROM
    user_spending us
JOIN
    orders o ON us.user_id = o.user_id
CROSS JOIN
    average_spending a
WHERE
    us.total_spent > a.avg_total
GROUP BY
    us.user_id
ORDER BY
    us.total_spent DESC
LIMIT 10

2. æœ‰RAGç”ŸæˆSQL...

ğŸ” æœ‰RAGç»“æœ
ç”Ÿæˆçš„SQL:
 SELECT AVG(total_amount) FROM orders)ã€‚

ä¸ºäº†æ»¡è¶³â€œé™åˆ¶10ä¸ªè¾“å‡ºâ€çš„è¦æ±‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨æœ€åæ·»åŠ LIMIT 10ã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œæœ€ç»ˆçš„SQLæŸ¥è¯¢è¯­å¥å¦‚ä¸‹ï¼š
SELECT u.username, COUNT(o.order_id) AS order_count, SUM(o.total_amount) AS total_spent
FROM users u
JOIN orders o ON u.user_id = o.user_id
GROUP BY u.user_id, u.username
HAVING total_spent > (SELECT AVG(total_amount) FROM orders)
ORDER BY total_spent DESC
LIMIT 10
````

## ç»“æœéªŒè¯

### åœºæ™¯1

æ— rag

```
ğŸ“Š ç»“æœ:
 user_id username              email
       1    user1  user1@example.com
       2    user2  user2@example.com
       3    user3  user3@example.com
       4    user4  user4@example.com
       5    user5  user5@example.com
       6    user6  user6@example.com
       7    user7  user7@example.com
       8    user8  user8@example.com
       9    user9  user9@example.com
      10   user10 user10@example.com
```

rag

```
ğŸ“Š ç»“æœ:
username              email registration_date
   user1  user1@example.com        2023-03-22
   user2  user2@example.com        2023-04-09
   user3  user3@example.com        2021-10-27
   user4  user4@example.com        2017-01-24
   user5  user5@example.com        2019-09-13
   user6  user6@example.com        2018-04-07
   user7  user7@example.com        2023-06-20
   user8  user8@example.com        2019-03-26
   user9  user9@example.com        2021-10-22
  user10 user10@example.com        2024-06-14
```

### åœºæ™¯2

æ— rag

```
âŒ æŸ¥è¯¢å¤±è´¥: 1054 (42S22): Unknown column 'address' in 'where clause'
```

rag

```
ğŸ“Š ç»“æœ:
 user_id username               email           phone first_name last_name  age gender     city country registration_date          last_login loyalty_level  total_orders total_spent          created_at
       2    user2   user2@example.com +1-555-950-1914       Lisa     Brown   39      F New York   China        2023-04-09 2023-04-13 08:30:50        Bronze           149     7833.91 2025-10-29 08:30:49
      49   user49  user49@example.com +1-555-942-4650      Sarah     Jones   59      F New York   India        2016-03-01 2016-08-25 08:30:50        Bronze            47     9372.28 2025-10-29 08:30:49
      90   user90  user90@example.com +1-555-668-8426       Lisa    Miller   76      M New York  France        2025-09-17 2026-05-06 08:30:50        Silver            39     6845.04 2025-10-29 08:30:49
     135  user135 user135@example.com +1-555-744-8384      David    Garcia   43      M New York  Canada        2025-07-30 2026-02-20 08:30:50        Silver           145     9263.39 2025-10-29 08:30:49
     181  user181 user181@example.com +1-555-539-7584       Jane  Williams   39      M New York Germany        2016-10-30 2017-08-06 08:30:50        Bronze            72     7338.95 2025-10-29 08:30:49
     182  user182 user182@example.com +1-555-420-1371       John     Jones   60      M New York  France        2018-03-11 2018-12-19 08:30:50      Platinum           180     8417.88 2025-10-29 08:30:49
     202  user202 user202@example.com +1-555-219-8654     Robert     Smith   24      F New York   China        2019-10-29 2019-12-06 08:30:50        Bronze            88     8262.60 2025-10-29 08:30:49
     204  user204 user204@example.com +1-555-162-6506      Emily     Smith   60      M New York  France        2016-12-17 2016-12-30 08:30:50        Silver           182     3735.68 2025-10-29 08:30:49
     228  user228 user228@example.com +1-555-394-6672      Emily    Miller   33      M New York  France        2021-03-20 2021-12-29 08:30:50        Bronze           140     1611.82 2025-10-29 08:30:49
     236  user236 user236@example.com +1-555-707-2542       Jane     Brown   19      M New York  Canada        2024-06-22 2025-03-08 08:30:50        Bronze           127     3983.92 2025-10-29 08:30:49
```

### åœºæ™¯3

æ— rag

```
âŒ æŸ¥è¯¢å¤±è´¥: 1054 (42S22): Unknown column 'c.id' in 'on clause'
```

rag

```
ğŸ“Š ç»“æœ:
 product_id   product_name                                         description  category_id  subcategory_id         brand   price cost_price  stock_quantity  min_stock_level weight dimensions  color size  is_active rating  review_count          created_at          updated_at     category_name  parent_category_id  level
          1 Uniqlo Dress 1 High-quality Uniqlo Dress 1 with excellent features            4               3        Levi's  240.62     154.77             240               10   1.45 49x18x26cm   Blue    S          1   3.65           362 2025-10-29 08:30:49 2025-10-29 08:30:49 Sports & Outdoors                 NaN      1
          2      Product 2      High-quality Product 2 with excellent features           15               4       Penguin  251.41     161.00             399               10   3.39 31x32x27cm  Black    S          1   4.35           145 2025-10-29 08:30:49 2025-10-29 08:30:49       Accessories                 2.0      1
          3      Product 3      High-quality Product 3 with excellent features            7               3        Scotts  307.05     118.62             625               10  19.80 50x33x39cm    Red   XL          1   4.60           230 2025-10-29 08:30:49 2025-10-29 08:30:49           Laptops                 1.0      1
          4      Product 4      High-quality Product 4 with excellent features            8               1          IKEA  227.15     104.05             108               10   9.10 44x34x25cm Silver    L          1   4.86           228 2025-10-29 08:30:49 2025-10-29 08:30:49           Tablets                 1.0      1
          5      Product 5      High-quality Product 5 with excellent features            8               2        Scotts   66.66      32.71              63               10   6.45  25x43x3cm    Red    M          1   4.47           161 2025-10-29 08:30:49 2025-10-29 08:30:49           Tablets                 1.0      1
          6      Product 6      High-quality Product 6 with excellent features           13               4 HarperCollins  217.95     106.58             400               10   6.16 21x31x45cm Silver  XXL          1   4.40           480 2025-10-29 08:30:49 2025-10-29 08:30:49     Kids Clothing                 2.0      1
          7    H&M Jeans 7    High-quality H&M Jeans 7 with excellent features            4               1         Gucci  285.82     109.71             139               10  17.41  25x46x2cm   Blue    S          1   3.91           376 2025-10-29 08:30:49 2025-10-29 08:30:49 Sports & Outdoors                 NaN      1
          8      Product 8      High-quality Product 8 with excellent features           14               5 HarperCollins  386.62     230.31             370               10  10.06  6x46x16cm  Black    L          1   4.43           290 2025-10-29 08:30:49 2025-10-29 08:30:49             Shoes                 2.0      1
          9 Nikon Tablet 9 High-quality Nikon Tablet 9 with excellent features            3               4         Canon 1149.95     589.28             249               10  10.62 42x25x21cm  Black    L          1   3.75           451 2025-10-29 08:30:49 2025-10-29 08:30:49     Home & Garden                 NaN      1
         10     Product 10     High-quality Product 10 with excellent features           10               2        Wilson  381.65     212.77             821               10   3.25  31x11x6cm Silver    L          1   3.56           304 2025-10-29 08:30:49 2025-10-29 08:30:49           Cameras                 1.0      1

```

### åœºæ™¯4

æ— rag

```
ğŸ“Š ç»“æœ:
        city  user_count
      London         288
    Shanghai         274
Philadelphia         272
     Beijing         268
 San Antonio         267
 Los Angeles         259
     Houston         256
       Tokyo         253
    New York         250
      Dallas         249
```

rag

```
ğŸ“Š ç»“æœ:
        city  user_count
      London         288
    Shanghai         274
Philadelphia         272
     Beijing         268
 San Antonio         267
 Los Angeles         259
     Houston         256
       Tokyo         253
    New York         250
      Dallas         249
```



### åœºæ™¯5

æ— rag

```
âŒ æŸ¥è¯¢å¤±è´¥: 1054 (42S22): Unknown column 'oi.price' in 'field list'
```

rag

```
ğŸ“Š ç»“æœ:
username total_spent
user3767    15698.88
user3476    15503.19
user3072    15143.47
 user621    15058.63
user1375    14872.05
user1112    14825.29
user3535    14575.35
user3614    14504.12
user3589    14492.77
 user690    14213.22
```



### åœºæ™¯6

æ— rag

```
ğŸ“Š ç»“æœ:
 user_id username registration_date          last_login         city
       1    user1        2023-03-22 2023-10-21 08:30:50  Los Angeles
       2    user2        2023-04-09 2023-04-13 08:30:50     New York
       3    user3        2021-10-27 2022-02-20 08:30:50      Phoenix
       4    user4        2017-01-24 2017-02-26 08:30:50      Houston
       5    user5        2019-09-13 2020-05-28 08:30:50      Beijing
       6    user6        2018-04-07 2018-10-30 08:30:50      Phoenix
       7    user7        2023-06-20 2024-03-23 08:30:50       Berlin
       8    user8        2019-03-26 2019-05-21 08:30:50      Beijing
       9    user9        2021-10-22 2021-11-20 08:30:50 Philadelphia
      10   user10        2024-06-14 2025-05-07 08:30:50       Sydney
```

rag

```
âŒ æŸ¥è¯¢å¤±è´¥: 1054 (42S22): Unknown column 'last_login_time' in 'field list'
```



### åœºæ™¯7

æ— rag

```
ğŸ“Š ç»“æœ:
 order_id username        product_name  quantity unit_price
     1142    user1 Uniqlo T-Shirt 2005         2     497.69
     1142    user1        Product 2262         2      11.81
     1142    user1   Prada Jacket 1433         1     459.25
     4206    user1   Levi's Jeans 1485         1      32.08
    14563    user1       HP Camera 453         4      32.75
    14563    user1        Product 1970         4     449.04
    18471    user1          Product 30         5     207.36
    18471    user1    Dell Tablet 1868         1      31.58
    18471    user1     Dell Tablet 267         2     104.26
    18471    user1         Product 660         2      12.94
```

rag

```
ğŸ“Š ç»“æœ:
 order_id username        product_name  quantity unit_price
     1142    user1 Uniqlo T-Shirt 2005         2     497.69
     1142    user1        Product 2262         2      11.81
     1142    user1   Prada Jacket 1433         1     459.25
     4206    user1   Levi's Jeans 1485         1      32.08
    14563    user1       HP Camera 453         4      32.75
    14563    user1        Product 1970         4     449.04
    18471    user1          Product 30         5     207.36
    18471    user1    Dell Tablet 1868         1      31.58
    18471    user1     Dell Tablet 267         2     104.26
    18471    user1         Product 660         2      12.94
```



### åœºæ™¯8

æ— rag

```
âŒ æŸ¥è¯¢å¤±è´¥: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'c.name AS category_name,
    AVG(p.price) AS average_price,
    COUNT(*) AS prod' at line 1
```

rag

```
ğŸ“Š ç»“æœ:
 category_name   avg_price  product_count
      Clothing 1061.695333            150
   Electronics 1017.906711            152
 Home & Garden  961.963832            167
    Headphones  262.818917            157
   Accessories  261.789302            172
         Shoes  261.335196            179
 Kids Clothing  260.996222            180
  Men Clothing  258.119659            176
Women Clothing  256.068304            171
       Laptops  256.044136            162
```



### åœºæ™¯9

æ— rag

```
âŒ æŸ¥è¯¢å¤±è´¥: 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'LIMIT 10' at line 6
```

rag

```
â„¹ï¸  æŸ¥è¯¢æˆåŠŸï¼Œä½†æœªè¿”å›æ•°æ®
```



### åœºæ™¯10

æ— rag

```
âŒ æŸ¥è¯¢å¤±è´¥: 1054 (42S22): Unknown column 'oi.price' in 'field list'
```

rag

```
ğŸ“Š ç»“æœ:
username  order_count total_spent
user3767           10    15698.88
user3476           14    15503.19
user3072           15    15143.47
 user621           12    15058.63
user1375           11    14872.05
user1112           11    14825.29
user3535           15    14575.35
user3614           10    14504.12
user3589           13    14492.77
 user690           12    14213.22
```

## å‡†ç¡®ç‡åˆ†æ

æ— rag

å‡†ç¡®ç‡=4/10=40%

rag

å‡†ç¡®ç‡=9/10 =90%

# é™„å½•

## ä»“åº“åœ°å€



## æ ¸å¿ƒæºä»£ç 

### create_mid_database.py //åˆ›å»ºæ•°æ®åº“

```
import mysql.connector
import random
import string
from datetime import datetime, timedelta
import time

class MidDatabaseCreator:
    def __init__(self, db_config):
        self.db_config = db_config
        self.conn = None
        self.cursor = None
    
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = mysql.connector.connect(**self.db_config)
        self.cursor = self.conn.cursor()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    
    def create_tables(self):
        """åˆ›å»ºä¸­ç­‰è§„æ¨¡ä¸šåŠ¡è¡¨ç»“æ„"""
        print("ğŸ—ƒï¸ åˆ›å»ºä¸­ç­‰è§„æ¨¡ä¸šåŠ¡è¡¨ç»“æ„...")
        
        # ç”¨æˆ·è¡¨ - 5,000ç”¨æˆ· (åŸ10ä¸‡çš„1/20)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                user_id INT PRIMARY KEY AUTO_INCREMENT,
                username VARCHAR(50) UNIQUE NOT NULL,
                email VARCHAR(100) UNIQUE NOT NULL,
                phone VARCHAR(20),
                first_name VARCHAR(50),
                last_name VARCHAR(50),
                age INT,
                gender ENUM('M', 'F', 'O'),
                city VARCHAR(50),
                country VARCHAR(50),
                registration_date DATE,
                last_login DATETIME,
                loyalty_level ENUM('Bronze', 'Silver', 'Gold', 'Platinum'),
                total_orders INT DEFAULT 0,
                total_spent DECIMAL(12,2) DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_city (city),
                INDEX idx_country (country),
                INDEX idx_registration (registration_date),
                INDEX idx_loyalty (loyalty_level)
            )
        """)
        
        # äº§å“è¡¨ - 2,500äº§å“ (åŸ5ä¸‡çš„1/20)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS products (
                product_id INT PRIMARY KEY AUTO_INCREMENT,
                product_name VARCHAR(200) NOT NULL,
                description TEXT,
                category_id INT,
                subcategory_id INT,
                brand VARCHAR(100),
                price DECIMAL(10,2) NOT NULL,
                cost_price DECIMAL(10,2),
                stock_quantity INT DEFAULT 0,
                min_stock_level INT DEFAULT 10,
                weight DECIMAL(8,2),
                dimensions VARCHAR(50),
                color VARCHAR(30),
                size VARCHAR(20),
                is_active BOOLEAN DEFAULT TRUE,
                rating DECIMAL(3,2) DEFAULT 0,
                review_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_category (category_id),
                INDEX idx_brand (brand),
                INDEX idx_price (price),
                INDEX idx_active (is_active)
            )
        """)
        
        # åˆ†ç±»è¡¨
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS categories (
                category_id INT PRIMARY KEY AUTO_INCREMENT,
                category_name VARCHAR(100) NOT NULL,
                parent_category_id INT,
                description TEXT,
                level INT DEFAULT 1,
                product_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_parent (parent_category_id)
            )
        """)
        
        # è®¢å•è¡¨ - 25,000è®¢å• (åŸ50ä¸‡çš„1/20)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS orders (
                order_id INT PRIMARY KEY AUTO_INCREMENT,
                user_id INT NOT NULL,
                order_date DATETIME NOT NULL,
                status ENUM('pending', 'confirmed', 'shipped', 'delivered', 'cancelled', 'refunded'),
                total_amount DECIMAL(12,2) NOT NULL,
                shipping_cost DECIMAL(8,2) DEFAULT 0,
                tax_amount DECIMAL(8,2) DEFAULT 0,
                discount_amount DECIMAL(8,2) DEFAULT 0,
                payment_method ENUM('credit_card', 'debit_card', 'paypal', 'bank_transfer', 'cash'),
                payment_status ENUM('pending', 'paid', 'failed', 'refunded'),
                shipping_address TEXT,
                billing_address TEXT,
                tracking_number VARCHAR(100),
                estimated_delivery DATE,
                actual_delivery DATE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
                INDEX idx_user (user_id),
                INDEX idx_order_date (order_date),
                INDEX idx_status (status),
                INDEX idx_payment_status (payment_status)
            )
        """)
        
        # è®¢å•è¯¦æƒ…è¡¨ - 100,000è®¢å•é¡¹ (åŸ200ä¸‡çš„1/20)
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS order_items (
                order_item_id INT PRIMARY KEY AUTO_INCREMENT,
                order_id INT NOT NULL,
                product_id INT NOT NULL,
                quantity INT NOT NULL,
                unit_price DECIMAL(10,2) NOT NULL,
                discount DECIMAL(8,2) DEFAULT 0,
                line_total DECIMAL(10,2) AS (quantity * (unit_price - discount)),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_order (order_id),
                INDEX idx_product (product_id)
            )
        """)
        
        # åº“å­˜è¡¨
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS inventory (
                inventory_id INT PRIMARY KEY AUTO_INCREMENT,
                product_id INT NOT NULL,
                warehouse_id INT,
                quantity INT NOT NULL,
                reserved_quantity INT DEFAULT 0,
                available_quantity INT AS (quantity - reserved_quantity),
                last_restock_date DATE,
                next_restock_date DATE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_product (product_id),
                INDEX idx_warehouse (warehouse_id)
            )
        """)
        
        # è¯„è®ºè¡¨
        self.cursor.execute("""
            CREATE TABLE IF NOT EXISTS reviews (
                review_id INT PRIMARY KEY AUTO_INCREMENT,
                user_id INT NOT NULL,
                product_id INT NOT NULL,
                order_id INT,
                rating INT NOT NULL CHECK (rating BETWEEN 1 AND 5),
                title VARCHAR(200),
                comment TEXT,
                is_verified_purchase BOOLEAN DEFAULT FALSE,
                helpful_votes INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_user (user_id),
                INDEX idx_product (product_id),
                INDEX idx_rating (rating)
            )
        """)
        
        print("âœ… è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")
    
    def generate_categories(self):
        """ç”Ÿæˆäº§å“åˆ†ç±»"""
        print("ğŸ“‚ ç”Ÿæˆäº§å“åˆ†ç±»...")
        
        categories = [
            # ä¸€çº§åˆ†ç±»
            ('Electronics', None, 'Electronic devices and accessories'),
            ('Clothing', None, 'Fashion and apparel'),
            ('Home & Garden', None, 'Home improvement and garden supplies'),
            ('Sports & Outdoors', None, 'Sports equipment and outdoor gear'),
            ('Books & Media', None, 'Books, movies, and music'),
            
            # ç”µå­äº§å“å­åˆ†ç±»
            ('Smartphones', 1, 'Mobile phones and smartphones'),
            ('Laptops', 1, 'Laptops and notebooks'),
            ('Tablets', 1, 'Tablets and e-readers'),
            ('Headphones', 1, 'Audio headphones and earphones'),
            ('Cameras', 1, 'Digital cameras and accessories'),
            
            # æœè£…å­åˆ†ç±»
            ('Men Clothing', 2, "Men's fashion and apparel"),
            ('Women Clothing', 2, "Women's fashion and apparel"),
            ('Kids Clothing', 2, "Children's clothing"),
            ('Shoes', 2, 'Footwear for all ages'),
            ('Accessories', 2, 'Fashion accessories'),
        ]
        
        for category in categories:
            self.cursor.execute(
                "INSERT INTO categories (category_name, parent_category_id, description) VALUES (%s, %s, %s)",
                category
            )
        
        self.conn.commit()
        print("âœ… åˆ†ç±»æ•°æ®ç”Ÿæˆå®Œæˆ")
    
    def generate_users(self, count=5000):
        """ç”Ÿæˆç”¨æˆ·æ•°æ®"""
        print(f"ğŸ‘¥ ç”Ÿæˆ {count} ä¸ªç”¨æˆ·æ•°æ®...")
        
        cities = ['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 
                 'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'London', 'Paris', 'Tokyo',
                 'Beijing', 'Shanghai', 'Mumbai', 'Sydney', 'Berlin', 'Toronto', 'Singapore']
        
        countries = ['USA', 'UK', 'Canada', 'Australia', 'Germany', 'France', 'Japan', 'China', 'India']
        
        loyalty_levels = ['Bronze', 'Silver', 'Gold', 'Platinum']
        
        batch_size = 500
        for batch in range(0, count, batch_size):
            current_batch = min(batch_size, count - batch)
            user_data = []
            
            for i in range(current_batch):
                user_id = batch + i + 1
                username = f"user{user_id}"
                email = f"user{user_id}@example.com"
                first_name = random.choice(['John', 'Jane', 'Mike', 'Sarah', 'David', 'Lisa', 'Robert', 'Emily'])
                last_name = random.choice(['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia', 'Miller', 'Davis'])
                age = random.randint(18, 80)
                gender = random.choice(['M', 'F'])
                city = random.choice(cities)
                country = random.choice(countries)
                registration_date = datetime.now() - timedelta(days=random.randint(1, 3650))
                last_login = registration_date + timedelta(days=random.randint(1, 365))
                loyalty = random.choices(loyalty_levels, weights=[0.4, 0.3, 0.2, 0.1])[0]
                total_orders = random.randint(0, 200)
                total_spent = round(random.uniform(0, 10000), 2)
                
                user_data.append((
                    username, email, f"+1-555-{random.randint(100,999)}-{random.randint(1000,9999)}",
                    first_name, last_name, age, gender, city, country, registration_date,
                    last_login, loyalty, total_orders, total_spent
                ))
            
            # æ‰¹é‡æ’å…¥
            insert_sql = """
                INSERT INTO users (username, email, phone, first_name, last_name, age, gender, 
                city, country, registration_date, last_login, loyalty_level, total_orders, total_spent)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            self.cursor.executemany(insert_sql, user_data)
            self.conn.commit()
            
            if (batch // batch_size) % 10 == 0:
                print(f"  å·²ç”Ÿæˆ {batch + current_batch} ä¸ªç”¨æˆ·")
        
        print("âœ… ç”¨æˆ·æ•°æ®ç”Ÿæˆå®Œæˆ")
    
    def generate_products(self, count=2500):
        """ç”Ÿæˆäº§å“æ•°æ®"""
        print(f"ğŸ“¦ ç”Ÿæˆ {count} ä¸ªäº§å“æ•°æ®...")
        
        brands = {
            'Electronics': ['Apple', 'Samsung', 'Sony', 'LG', 'Dell', 'HP', 'Canon', 'Nikon'],
            'Clothing': ['Nike', 'Adidas', 'Zara', 'H&M', 'Uniqlo', 'Levi\'s', 'Gucci', 'Prada'],
            'Home & Garden': ['IKEA', 'Home Depot', 'Black & Decker', 'Scotts', 'Weber'],
            'Sports & Outdoors': ['Nike', 'Adidas', 'Under Armour', 'Wilson', 'Spalding'],
            'Books & Media': ['Penguin', 'HarperCollins', 'Random House', 'Disney', 'Warner Bros']
        }
        
        batch_size = 500
        for batch in range(0, count, batch_size):
            current_batch = min(batch_size, count - batch)
            product_data = []
            
            for i in range(current_batch):
                product_id = batch + i + 1
                category_id = random.randint(1, 15)
                main_category = (category_id - 1) // 3 + 1
                
                if main_category == 1:  # Electronics
                    product_name = f"{random.choice(brands['Electronics'])} {random.choice(['Smartphone', 'Laptop', 'Tablet', 'Headphones', 'Camera'])} {product_id}"
                    price = round(random.uniform(50, 2000), 2)
                elif main_category == 2:  # Clothing
                    product_name = f"{random.choice(brands['Clothing'])} {random.choice(['T-Shirt', 'Jeans', 'Dress', 'Jacket', 'Shoes'])} {product_id}"
                    price = round(random.uniform(10, 300), 2)
                else:  # Other categories
                    product_name = f"Product {product_id}"
                    price = round(random.uniform(5, 500), 2)
                
                description = f"High-quality {product_name} with excellent features"
                brand = random.choice(brands.get(list(brands.keys())[main_category-1], ['Generic']))
                cost_price = round(price * random.uniform(0.3, 0.7), 2)
                stock_quantity = random.randint(0, 1000)
                weight = round(random.uniform(0.1, 20), 2)
                rating = round(random.uniform(3.0, 5.0), 2)
                review_count = random.randint(0, 500)
                
                product_data.append((
                    product_name, description, category_id, random.randint(1, 5),
                    brand, price, cost_price, stock_quantity, 10, weight,
                    f"{random.randint(1,50)}x{random.randint(1,50)}x{random.randint(1,50)}cm",
                    random.choice(['Black', 'White', 'Red', 'Blue', 'Silver']),
                    random.choice(['S', 'M', 'L', 'XL', 'XXL']), True, rating, review_count
                ))
            
            # æ‰¹é‡æ’å…¥
            insert_sql = """
                INSERT INTO products (product_name, description, category_id, subcategory_id, 
                brand, price, cost_price, stock_quantity, min_stock_level, weight, dimensions, 
                color, size, is_active, rating, review_count)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            self.cursor.executemany(insert_sql, product_data)
            self.conn.commit()
            
            if (batch // batch_size) % 5 == 0:
                print(f"  å·²ç”Ÿæˆ {batch + current_batch} ä¸ªäº§å“")
        
        print("âœ… äº§å“æ•°æ®ç”Ÿæˆå®Œæˆ")
    
    def generate_orders(self, count=25000):
        """ç”Ÿæˆè®¢å•æ•°æ®"""
        print(f"ğŸ›’ ç”Ÿæˆ {count} ä¸ªè®¢å•æ•°æ®...")
        
        status_weights = [0.1, 0.2, 0.3, 0.3, 0.05, 0.05]  # pending, confirmed, shipped, delivered, cancelled, refunded
        payment_methods = ['credit_card', 'debit_card', 'paypal', 'bank_transfer', 'cash']
        payment_status_weights = [0.05, 0.9, 0.03, 0.02]  # pending, paid, failed, refunded
        
        batch_size = 2500
        for batch in range(0, count, batch_size):
            current_batch = min(batch_size, count - batch)
            order_data = []
            
            for i in range(current_batch):
                order_id = batch + i + 1
                user_id = random.randint(1, 5000)
                order_date = datetime.now() - timedelta(days=random.randint(1, 365))
                status = random.choices(['pending', 'confirmed', 'shipped', 'delivered', 'cancelled', 'refunded'], 
                                      weights=status_weights)[0]
                total_amount = round(random.uniform(10, 2000), 2)
                shipping_cost = round(random.uniform(0, 50), 2)
                tax_amount = round(total_amount * 0.08, 2)
                discount_amount = round(total_amount * random.uniform(0, 0.3), 2)
                payment_method = random.choice(payment_methods)
                payment_status = random.choices(['pending', 'paid', 'failed', 'refunded'], 
                                              weights=payment_status_weights)[0]
                
                order_data.append((
                    user_id, order_date, status, total_amount, shipping_cost, tax_amount,
                    discount_amount, payment_method, payment_status,
                    f"{random.randint(100,999)} Main St, City{random.randint(1,100)}",
                    f"{random.randint(100,999)} Main St, City{random.randint(1,100)}",
                    f"TRK{order_id:08d}",
                    order_date + timedelta(days=random.randint(3, 14)),
                    order_date + timedelta(days=random.randint(5, 21)) if status in ['delivered', 'shipped'] else None
                ))
            
            # æ‰¹é‡æ’å…¥
            insert_sql = """
                INSERT INTO orders (user_id, order_date, status, total_amount, shipping_cost, 
                tax_amount, discount_amount, payment_method, payment_status, shipping_address, 
                billing_address, tracking_number, estimated_delivery, actual_delivery)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """
            self.cursor.executemany(insert_sql, order_data)
            self.conn.commit()
            
            if (batch // batch_size) % 10 == 0:
                print(f"  å·²ç”Ÿæˆ {batch + current_batch} ä¸ªè®¢å•")
        
        print("âœ… è®¢å•æ•°æ®ç”Ÿæˆå®Œæˆ")
    
    def generate_order_items(self, count=100000):
        """ç”Ÿæˆè®¢å•é¡¹æ•°æ®"""
        print(f"ğŸ“‹ ç”Ÿæˆ {count} ä¸ªè®¢å•é¡¹æ•°æ®...")
        
        batch_size = 5000
        for batch in range(0, count, batch_size):
            current_batch = min(batch_size, count - batch)
            order_item_data = []
            
            for i in range(current_batch):
                order_item_id = batch + i + 1
                order_id = random.randint(1, 25000)
                product_id = random.randint(1, 2500)
                quantity = random.randint(1, 5)
                unit_price = round(random.uniform(5, 500), 2)
                discount = round(unit_price * random.uniform(0, 0.2), 2)
                
                order_item_data.append((
                    order_id, product_id, quantity, unit_price, discount
                ))
            
            # æ‰¹é‡æ’å…¥
            insert_sql = """
                INSERT INTO order_items (order_id, product_id, quantity, unit_price, discount)
                VALUES (%s, %s, %s, %s, %s)
            """
            self.cursor.executemany(insert_sql, order_item_data)
            self.conn.commit()
            
            if (batch // batch_size) % 20 == 0:
                print(f"  å·²ç”Ÿæˆ {batch + current_batch} ä¸ªè®¢å•é¡¹")
        
        print("âœ… è®¢å•é¡¹æ•°æ®ç”Ÿæˆå®Œæˆ")
    
    def create_all_data(self):
        """åˆ›å»ºæ‰€æœ‰æ•°æ®"""
        start_time = time.time()
        
        self.connect()
        self.create_tables()
        self.generate_categories()
        self.generate_users(5000)        # 5,000ç”¨æˆ·
        self.generate_products(2500)     # 2,500äº§å“
        self.generate_orders(25000)      # 25,000è®¢å•
        self.generate_order_items(100000)  # 100,000è®¢å•é¡¹
        
        end_time = time.time()
        print(f"\nğŸ‰ æ‰€æœ‰æ•°æ®ç”Ÿæˆå®Œæˆï¼è€—æ—¶: {end_time - start_time:.2f} ç§’")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        self.show_statistics()
    
    def show_statistics(self):
        """æ˜¾ç¤ºæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "="*50)
        print("ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
        print("="*50)
        
        tables = ['users', 'products', 'orders', 'order_items', 'categories', 'reviews', 'inventory']
        
        for table in tables:
            try:
                self.cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = self.cursor.fetchone()[0]
                print(f"{table:15} : {count:>10,} è¡Œ")
            except:
                print(f"{table:15} : {'è¡¨ä¸å­˜åœ¨':>10}")
        
        # æ˜¾ç¤ºå…³ç³»ç»Ÿè®¡
        print("\nğŸ”— æ•°æ®å…³ç³»ç»Ÿè®¡:")
        self.cursor.execute("""
            SELECT 'å¹³å‡è®¢å•é‡‘é¢' as metric, ROUND(AVG(total_amount), 2) as value FROM orders
            UNION ALL
            SELECT 'æ€»ç”¨æˆ·æ•°', COUNT(*) FROM users  
            UNION ALL
            SELECT 'æ´»è·ƒäº§å“æ•°', COUNT(*) FROM products WHERE is_active = TRUE
            UNION ALL
            SELECT 'å¹³å‡è®¢å•é¡¹æ•°', ROUND(AVG(item_count), 2) FROM (
                SELECT order_id, COUNT(*) as item_count FROM order_items GROUP BY order_id
            ) as order_counts
        """)
        
        for metric, value in self.cursor.fetchall():
            print(f"  {metric:20} : {value:>15}")

def main():
    db_config = {
        'host': 'localhost',
        'user': 'root',
        'password': 'admin',
        'database': 'test_rag_mid'  # ä¸­ç­‰è§„æ¨¡æ•°æ®åº“
    }
    
    # é¦–å…ˆåˆ›å»ºæ•°æ®åº“
    try:
        conn = mysql.connector.connect(
            host=db_config['host'],
            user=db_config['user'],
            password=db_config['password']
        )
        cursor = conn.cursor()
        cursor.execute(f"CREATE DATABASE IF NOT EXISTS {db_config['database']}")
        cursor.close()
        conn.close()
        print(f"âœ… æ•°æ®åº“ {db_config['database']} åˆ›å»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åº“åˆ›å»ºå¤±è´¥: {e}")
        return
    
    # åˆ›å»ºä¸­ç­‰è§„æ¨¡æ•°æ®
    creator = MidDatabaseCreator(db_config)
    creator.create_all_data()

if __name__ == "__main__":
    main()
```

### database_rag_system.py //ragæµ‹è¯•ç³»ç»Ÿ

```
# enhanced_rag_comparison.py
import os
import mysql.connector
import torch
import pandas as pd
from typing import List, Dict, Any, Tuple
import re

from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.llms import HuggingFacePipeline
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline


class DatabaseKnowledgeExtractor:
    def __init__(self, db_config, model_path):
        self.db_config = db_config
        self.model_path = model_path
        self.conn = None
        self.cursor = None
        
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = mysql.connector.connect(**self.db_config)
        self.cursor = self.conn.cursor(dictionary=True)
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    
    def extract_schema_info(self):
        """æå–æ•°æ®åº“æ¨¡å¼ä¿¡æ¯"""
        schema_info = {
            "tables": {},
            "relationships": [],
            "statistics": {}
        }
        
        # è·å–æ‰€æœ‰è¡¨
        self.cursor.execute("SHOW TABLES")
        tables = [list(table.values())[0] for table in self.cursor.fetchall()]
        
        for table in tables:
            # è·å–è¡¨ç»“æ„
            self.cursor.execute(f"DESCRIBE {table}")
            columns = self.cursor.fetchall()
            
            # è·å–ç´¢å¼•ä¿¡æ¯
            self.cursor.execute(f"SHOW INDEX FROM {table}")
            indexes = self.cursor.fetchall()
            
            schema_info["tables"][table] = {
                "columns": columns,
                "indexes": indexes
            }
            
            # è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯
            self.cursor.execute(f"SELECT COUNT(*) as count FROM {table}")
            count_result = self.cursor.fetchone()
            schema_info["statistics"][table] = {
                "row_count": count_result["count"]
            }
        
        # æå–å¤–é”®å…³ç³»ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        schema_info["relationships"] = self._extract_relationships()
        
        return schema_info
    
    def _extract_relationships(self):
        """æå–è¡¨ä¹‹é—´çš„å…³ç³»"""
        relationships = []
        
        # åŸºäºå‘½åçº¦å®šå’Œæ•°æ®åˆ†ææ¨æ–­å…³ç³»
        table_pairs = [
            ("users", "orders", "user_id"),
            ("products", "order_items", "product_id"),
            ("orders", "order_items", "order_id"),
            ("categories", "products", "category_id")
        ]
        
        for table1, table2, key in table_pairs:
            relationships.append({
                "table1": table1,
                "table2": table2,
                "relationship": f"{table1}.{key} = {table2}.{key}",
                "type": "foreign_key"
            })
        
        return relationships
    
    def extract_sample_data(self, sample_size=5):
        """æå–æ ·æœ¬æ•°æ®ç”¨äºç†è§£æ•°æ®åˆ†å¸ƒ"""
        sample_data = {}
        
        tables = ["users", "products", "orders", "order_items", "categories"]
        
        for table in tables:
            try:
                self.cursor.execute(f"SELECT * FROM {table} LIMIT {sample_size}")
                sample_data[table] = self.cursor.fetchall()
            except:
                print(f"æ— æ³•è·å–è¡¨ {table} çš„æ ·æœ¬æ•°æ®")
        
        return sample_data

class EnhancedRAGComparison:
    def __init__(self, db_config, model_path):
        self.db_config = db_config
        self.model_path = model_path
        self.conn = None
        self.cursor = None
        
    def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        self.conn = mysql.connector.connect(**self.db_config)
        self.cursor = self.conn.cursor(dictionary=True)
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
    
    def get_challenging_test_scenarios(self):

        """åˆ›å»ºæ›´å…·æŒ‘æˆ˜æ€§çš„æµ‹è¯•åœºæ™¯"""
        return [          
            {
                "name": "åœºæ™¯1: ç®€å•å•è¡¨æŸ¥è¯¢",
                "question": "æŸ¥è¯¢å‰10ä¸ªç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT user_id, username, email, city, country FROM users LIMIT 10"
            },
            {
                "name": "åœºæ™¯2: å¸¦æ¡ä»¶çš„å•è¡¨æŸ¥è¯¢", 
                "question": "æŸ¥è¯¢æ¥è‡ªçº½çº¦çš„ç”¨æˆ·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT * FROM users WHERE city = 'New York' LIMIT 10"
            },
            {
                "name": "åœºæ™¯3: ä¸¤è¡¨è¿æ¥æŸ¥è¯¢",
                "question": "æŸ¥è¯¢äº§å“åŠå…¶åˆ†ç±»ä¿¡æ¯ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT p.product_name, p.price, c.category_name FROM products p JOIN categories c ON p.category_id = c.category_id LIMIT 10"
            },
            {
                "name": "åœºæ™¯4: èšåˆæŸ¥è¯¢",
                "question": "ç»Ÿè®¡æ¯ä¸ªåŸå¸‚çš„ç”¨æˆ·æ•°é‡ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT city, COUNT(*) as user_count FROM users GROUP BY city ORDER BY user_count DESC LIMIT 10"
            },
            {
                "name": "åœºæ™¯5: å¤æ‚å¤šè¡¨è¿æ¥",
                "question": "æŸ¥è¯¢æ¯ä¸ªç”¨æˆ·çš„è®¢å•æ€»é‡‘é¢ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT u.username, SUM(o.total_amount) as total_spent FROM users u JOIN orders o ON u.user_id = o.user_id GROUP BY u.user_id, u.username ORDER BY total_spent DESC LIMIT 10"
            },
            # æ›´å…·æŒ‘æˆ˜æ€§çš„åœºæ™¯
            {
                "name": "åœºæ™¯6: å¤æ‚åˆ—åæŸ¥è¯¢",
                "question": "æŸ¥è¯¢ç”¨æˆ·çš„æ³¨å†Œæ—¥æœŸå’Œæœ€åç™»å½•æ—¶é—´ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€ç”¨æˆ·åå’ŒåŸå¸‚ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": "SELECT user_id, username, city, registration_date, last_login FROM users LIMIT 10",
                "challenge": "éœ€è¦çŸ¥é“å…·ä½“çš„æ—¥æœŸæ—¶é—´åˆ—å"
            },
            {
                "name": "åœºæ™¯7: å¤šè¡¨è¿æ¥ä¸ç‰¹å®šåˆ—", 
                "question": "æŸ¥è¯¢è®¢å•è¯¦æƒ…ï¼ŒåŒ…æ‹¬è®¢å•IDã€ç”¨æˆ·åã€äº§å“åç§°ã€æ•°é‡å’Œå•ä»·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT o.order_id, u.username, p.product_name, oi.quantity, oi.unit_price 
FROM orders o 
JOIN users u ON o.user_id = u.user_id 
JOIN order_items oi ON o.order_id = oi.order_id 
JOIN products p ON oi.product_id = p.product_id 
LIMIT 10""",
                "challenge": "éœ€è¦çŸ¥é“å››è¡¨è¿æ¥å’Œæ­£ç¡®çš„åˆ—å"
            },
            {
                "name": "åœºæ™¯8: èšåˆå‡½æ•°ä¸åˆ†ç»„",
                "question": "ç»Ÿè®¡æ¯ä¸ªäº§å“ç±»åˆ«çš„å¹³å‡ä»·æ ¼å’Œäº§å“æ•°é‡ï¼ŒæŒ‰å¹³å‡ä»·æ ¼é™åºæ’åˆ—ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT c.category_name, 
AVG(p.price) as avg_price, 
COUNT(p.product_id) as product_count 
FROM products p 
JOIN categories c ON p.category_id = c.category_id 
GROUP BY c.category_id, c.category_name 
ORDER BY avg_price DESC""",
                "challenge": "éœ€è¦çŸ¥é“èšåˆå‡½æ•°å’Œåˆ†ç»„é€»è¾‘"
            },
            {
                "name": "åœºæ™¯9: å¤æ‚æ¡ä»¶æŸ¥è¯¢",
                "question": "æŸ¥è¯¢æœ€è¿‘30å¤©å†…æ³¨å†Œä¸”æ¥è‡ªç¾å›½çº½çº¦çš„é»„é‡‘ç­‰çº§ç”¨æˆ·ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT user_id, username, email, city, loyalty_level, registration_date 
FROM users 
WHERE city = 'New York' 
AND country = 'USA' 
AND loyalty_level = 'Gold' 
AND registration_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)""",
                "challenge": "éœ€è¦çŸ¥é“æ—¥æœŸå‡½æ•°å’Œå¤šä¸ªæ¡ä»¶"
            },
            {
                "name": "åœºæ™¯10: å­æŸ¥è¯¢ä¸é«˜çº§åˆ†æ",
                "question": "æŸ¥è¯¢æ¶ˆè´¹é‡‘é¢é«˜äºå¹³å‡æ¶ˆè´¹æ°´å¹³çš„ç”¨æˆ·åŠå…¶è®¢å•æ€»æ•°ï¼Œé™åˆ¶10ä¸ªè¾“å‡º",
                "expected_sql": """SELECT u.username, 
COUNT(o.order_id) as order_count, 
SUM(o.total_amount) as total_spent 
FROM users u 
JOIN orders o ON u.user_id = o.user_id 
GROUP BY u.user_id, u.username 
HAVING total_spent > (SELECT AVG(total_amount) FROM orders) 
ORDER BY total_spent DESC 
LIMIT 10""",
                "challenge": "éœ€è¦å­æŸ¥è¯¢å’ŒHAVINGå­å¥"
            }
        ]
    
    def execute_and_compare(self, sql_query, expected_sql, description):
        print(f"\nğŸ” {description}")
        print(f"ç”Ÿæˆçš„SQL:\n {sql_query}")
        # print(f"æœŸæœ›çš„SQL:\n {expected_sql}")
        
    


class AdvancedRAGSystem:
    def __init__(self, config, db_config):
        self.config = config
        self.db_config = db_config
        self.embeddings = self._init_embeddings()
        self.llm = self._init_llm()
        self.vector_db = None
        self.qa_chain = None
        
    def _init_embeddings(self):
        print("åŠ è½½BGE-M3åµŒå…¥æ¨¡å‹...")
        return HuggingFaceBgeEmbeddings(
            model_name=self.config.EMBEDDING_MODEL_NAME,
            model_kwargs={'device': 'cuda' if torch.cuda.is_available() else 'cpu'},
            encode_kwargs={'normalize_embeddings': True},
            query_instruction="ä¸ºè¿™ä¸ªå¥å­ç”Ÿæˆè¡¨ç¤ºä»¥ç”¨äºæ£€ç´¢ç›¸å…³æ–‡ç« ï¼š"
        )

    def _init_llm(self):
        print(f"åŠ è½½Qwen3æ¨¡å‹: {self.config.LLM_MODEL_NAME}")

        tokenizer = AutoTokenizer.from_pretrained(self.config.LLM_MODEL_NAME)
        model = AutoModelForCausalLM.from_pretrained(
            self.config.LLM_MODEL_NAME,
            device_map="cuda",
            torch_dtype=torch.bfloat16,
            trust_remote_code=True
        )

        pipe = pipeline(
            "text-generation",
            model=model,
            tokenizer=tokenizer,
            max_new_tokens=800,  # å¢åŠ tokenæ•°é‡å¤„ç†å¤æ‚SQL
            temperature=0.1,     # é™ä½éšæœºæ€§
            repetition_penalty=1.1,
            pad_token_id=tokenizer.pad_token_id,
            eos_token_id=tokenizer.eos_token_id,
        )

        return HuggingFacePipeline(pipeline=pipe)
    
    def load_rag_system(self):
        """åŠ è½½RAGç³»ç»Ÿ"""
        if os.path.exists(self.config.VECTOR_DB_DIR):
            print("åŠ è½½å·²æœ‰å‘é‡åº“...")
            self.vector_db = Chroma(
                persist_directory=self.config.VECTOR_DB_DIR,
                embedding_function=self.embeddings
            )
            
            # SQLç”Ÿæˆæç¤ºæ¨¡æ¿
            sql_prompt_template = """ä½ æ˜¯ä¸€ä¸ªSQLä¸“å®¶ã€‚åŸºäºä»¥ä¸‹æ•°æ®åº“ç»“æ„çŸ¥è¯†å’Œç”¨æˆ·é—®é¢˜ï¼Œç”Ÿæˆå‡†ç¡®ä¸”ä¼˜åŒ–çš„SQLæŸ¥è¯¢è¯­å¥ã€‚

æ•°æ®åº“ç»“æ„ä¿¡æ¯:
{context}

ç”¨æˆ·é—®é¢˜: {question}

è¯·éµå¾ªä»¥ä¸‹è§„åˆ™:
1. åªè¿”å›SQLæŸ¥è¯¢è¯­å¥ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Š
2. ä½¿ç”¨æ­£ç¡®çš„è¡¨åå’Œåˆ—å
3. åŒ…å«é€‚å½“çš„WHEREæ¡ä»¶ã€JOINæ¡ä»¶å’ŒGROUP BYå­å¥
4. å¯¹äºåˆ†é¡µæŸ¥è¯¢ä½¿ç”¨LIMIT
5. ç¡®ä¿SQLè¯­æ³•æ­£ç¡®

SQLæŸ¥è¯¢:"""
            
            sql_prompt = PromptTemplate(
                template=sql_prompt_template,
                input_variables=["context", "question"]
            )
            
            self.qa_chain = RetrievalQA.from_chain_type(
                llm=self.llm,
                chain_type="stuff",
                retriever=self.vector_db.as_retriever(search_kwargs={"k": self.config.TOP_K}),
                chain_type_kwargs={"prompt": sql_prompt},
                return_source_documents=True
            )
            return True
        return False
    
    def generate_sql_without_rag(self, question: str) -> str:
        """ä¸ä½¿ç”¨RAGç”ŸæˆSQLï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰"""
        prompt = f"""è¯·ä¸ºä»¥ä¸‹é—®é¢˜ç”ŸæˆSQLæŸ¥è¯¢è¯­å¥ã€‚æ•°æ®åº“åŒ…å«users, products, orders, order_items, categoriesç­‰è¡¨ã€‚

é—®é¢˜: {question}

è¯·åªè¿”å›SQLæŸ¥è¯¢è¯­å¥:"""
        
        result = self.llm.invoke(prompt)
        return self._extract_sql_from_response(result)
    
    def generate_sql_with_rag(self, question: str) -> Tuple[str, List]:
        """ä½¿ç”¨RAGç”ŸæˆSQL"""
        result = self.qa_chain.invoke({"query": question}) 
        sql = self._extract_sql_from_response(result["result"])
        return sql, result["source_documents"]
    
    def _extract_sql_from_response(self, response: str) -> str:
        """ä»å“åº”ä¸­æå–SQLè¯­å¥"""
        # æŸ¥æ‰¾SQLå¼€å§‹
        sql_start = -1
        sql_keywords = ["SELECT", "INSERT", "UPDATE", "DELETE", "WITH"]
        
        for keyword in sql_keywords:
            idx = response.upper().find(keyword)
            if idx != -1 and (sql_start == -1 or idx < sql_start):
                sql_start = idx
        
        if sql_start != -1:
            # æå–åˆ°åˆ†å·æˆ–ç»“å°¾
            sql_end = response.find(';', sql_start)
            if sql_end == -1:
                sql_end = len(response)
            
            sql = response[sql_start:sql_end].strip()
            # æ¸…ç†å¯èƒ½çš„Markdownä»£ç å—
            sql = re.sub(r'^```sql\s*|\s*```$', '', sql, flags=re.IGNORECASE)
            return sql.strip()
        
        return response.strip()


def generate_enhanced_overview(schema_info, sample_data):
    """ç”Ÿæˆæ•°æ®åº“æ¦‚è§ˆ"""
    content = "æ•°æ®åº“æ¦‚è§ˆ\n"
    content += "=" * 60 + "\n\n"
    
    content += "è¡¨ç»Ÿè®¡:\n"
    for table_name, stats in schema_info["statistics"].items():
        col_count = len(schema_info["tables"][table_name]["columns"])
        content += f"- {table_name}: {col_count}åˆ—, {stats['row_count']}è¡Œæ•°æ®\n"
    
    content += "\nå…³é”®å…³ç³»:\n"
    for rel in schema_info["relationships"]:
        content += f"- {rel['table1']} â†” {rel['table2']} ({rel['relationship']})\n"
    
    content += "\næ•°æ®ç‰¹å¾:\n"
    # æ·»åŠ æ•°æ®åˆ†å¸ƒä¿¡æ¯
    if 'users' in sample_data:
        cities = [user['city'] for user in sample_data['users'] if 'city' in user]
        if cities:
            content += f"- ç”¨æˆ·åŸå¸‚åˆ†å¸ƒç¤ºä¾‹: {', '.join(set(cities))}\n"
    
    return content


def generate_detailed_table_doc(table_name, table_info, sample_data):
    """ç”Ÿæˆè¯¦ç»†çš„è¡¨æ–‡æ¡£"""
    content = f"è¡¨è¯¦ç»†æ–‡æ¡£: {table_name}\n"
    content += "=" * 60 + "\n\n"
    
    content += "åˆ—è¯¦ç»†ä¿¡æ¯:\n"
    for col in table_info["columns"]:
        content += f"- {col['Field']}: {col['Type']} | Null: {col['Null']} | Key: {col['Key']} | Default: {col['Default']}\n"
    
    content += "\nç´¢å¼•ä¿¡æ¯:\n"
    for idx in table_info["indexes"]:
        content += f"- {idx['Column_name']} ({idx['Index_type']}) - {'å”¯ä¸€' if idx['Non_unique'] == 0 else 'éå”¯ä¸€'}\n"
    
    if sample_data:
        content += f"\næ•°æ®ç¤ºä¾‹ ({len(sample_data)} è¡Œ):\n"
        df = pd.DataFrame(sample_data)
        content += df.to_string() + "\n"
    
    return content


def generate_query_patterns():
    """ç”ŸæˆæŸ¥è¯¢æ¨¡å¼æ–‡æ¡£"""
    content = "å¸¸ç”¨æŸ¥è¯¢æ¨¡å¼\n"
    content += "=" * 60 + "\n\n"
    
    patterns = [
        {
            "pattern": "ç®€å•å•è¡¨æŸ¥è¯¢",
            "description": "æŸ¥è¯¢ç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯",
            "sql": "SELECT user_id, username, email, city, country FROM users"
        },
        {
            "pattern": "å¸¦æ¡ä»¶çš„å•è¡¨æŸ¥è¯¢",
            "description": "æŸ¥è¯¢æ¥è‡ªçº½çº¦çš„ç”¨æˆ·",
            "sql": "SELECT * FROM users WHERE city = 'New York'"
        },
        {
            "pattern": "ä¸¤è¡¨è¿æ¥æŸ¥è¯¢", 
            "description": "æŸ¥è¯¢äº§å“åŠå…¶åˆ†ç±»ä¿¡æ¯",
            "sql": "SELECT p.product_name, p.price, c.category_name FROM products p JOIN categories c ON p.category_id = c.category_id"
        },
        {
            "pattern": "èšåˆæŸ¥è¯¢",
            "description": "ç»Ÿè®¡æ¯ä¸ªåŸå¸‚çš„ç”¨æˆ·æ•°",
            "sql": "SELECT city, COUNT(*) as user_count FROM users GROUP BY city ORDER BY user_count DESC"
        },
        
        {
            "pattern": "å¤æ‚å¤šè¡¨è¿æ¥",
            "description": "æŸ¥è¯¢æ¯ä¸ªç”¨æˆ·çš„è®¢å•æ€»é‡‘é¢",
            "sql": "SELECT u.username, SUM(o.total_amount) as total_spent FROM users u JOIN orders o ON u.user_id = o.user_id GROUP BY u.user_id, u.username ORDER BY total_spent DESC"
        },
        {
            "pattern": " å¤æ‚åˆ—åæŸ¥è¯¢",
            "description": "æŸ¥è¯¢ç”¨æˆ·çš„æ³¨å†Œæ—¥æœŸå’Œæœ€åç™»å½•æ—¶é—´ï¼Œæ˜¾ç¤ºç”¨æˆ·IDã€ç”¨æˆ·åå’ŒåŸå¸‚",
            "sql": "SELECT user_id, username, city, registration_date, last_login FROM users"
        },
        {
            "pattern": " å¤šè¡¨è¿æ¥ä¸ç‰¹å®šåˆ—", 
            "description": "æŸ¥è¯¢è®¢å•è¯¦æƒ…ï¼ŒåŒ…æ‹¬è®¢å•IDã€ç”¨æˆ·åã€äº§å“åç§°ã€æ•°é‡å’Œå•ä»·",
            "sql": """SELECT o.order_id, u.username, p.product_name, oi.quantity, oi.unit_price 
FROM orders o 
JOIN users u ON o.user_id = u.user_id 
JOIN order_items oi ON o.order_id = oi.order_id 
JOIN products p ON oi.product_id = p.product_id """
        },
        {
            "pattern": " èšåˆå‡½æ•°ä¸åˆ†ç»„",
            "description": "ç»Ÿè®¡æ¯ä¸ªäº§å“ç±»åˆ«çš„å¹³å‡ä»·æ ¼å’Œäº§å“æ•°é‡ï¼ŒæŒ‰å¹³å‡ä»·æ ¼é™åºæ’åˆ—",
            "sql": """SELECT c.category_name, 
AVG(p.price) as avg_price, 
COUNT(p.product_id) as product_count 
FROM products p 
JOIN categories c ON p.category_id = c.category_id 
GROUP BY c.category_id, c.category_name 
ORDER BY avg_price DESC"""
        },
        {
            "pattern": " å¤æ‚æ¡ä»¶æŸ¥è¯¢",
            "description": "æŸ¥è¯¢æœ€è¿‘30å¤©å†…æ³¨å†Œä¸”æ¥è‡ªç¾å›½çº½çº¦çš„é»„é‡‘ç­‰çº§ç”¨æˆ·",
            "sql": """SELECT user_id, username, email, city, loyalty_level, registration_date 
FROM users 
WHERE city = 'New York' 
AND country = 'USA' 
AND loyalty_level = 'Gold' 
AND registration_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)"""
        },
        {
            "pattern": " å­æŸ¥è¯¢ä¸é«˜çº§åˆ†æ",
            "description": "æŸ¥è¯¢æ¶ˆè´¹é‡‘é¢é«˜äºå¹³å‡æ¶ˆè´¹æ°´å¹³çš„ç”¨æˆ·åŠå…¶è®¢å•æ€»æ•°",
            "sql": """SELECT u.username, 
COUNT(o.order_id) as order_count, 
SUM(o.total_amount) as total_spent 
FROM users u 
JOIN orders o ON u.user_id = o.user_id 
GROUP BY u.user_id, u.username 
HAVING total_spent > (SELECT AVG(total_amount) FROM orders) 
ORDER BY total_spent DESC """
        }
    ]
    
    for pattern in patterns:
        content += f"{pattern['pattern']}:\n"
        content += f"æè¿°: {pattern['description']}\n"
        content += f"SQLæ¨¡å¼: {pattern['sql']}\n\n"
    
    return content


def generate_business_logic():
    """ç”Ÿæˆä¸šåŠ¡é€»è¾‘æ–‡æ¡£"""
    content = "ä¸šåŠ¡é€»è¾‘å’Œè§„åˆ™\n"
    content += "=" * 60 + "\n\n"
    
    business_rules = [
        "ç”¨æˆ·å¿ è¯šåº¦ç­‰çº§: Bronze(é’é“œ) < Silver(ç™½é“¶) < Gold(é»„é‡‘) < Platinum(ç™½é‡‘)",
        "è®¢å•çŠ¶æ€æµè½¬: pending(å¾…å¤„ç†) â†’ confirmed(å·²ç¡®è®¤) â†’ shipped(å·²å‘è´§) â†’ delivered(å·²é€è¾¾)",
        "æ”¯ä»˜çŠ¶æ€: pending(å¾…æ”¯ä»˜) â†’ paid(å·²æ”¯ä»˜) â†’ refunded(å·²é€€æ¬¾)",
        "åº“å­˜é¢„è­¦: å½“stock_quantity <= min_stock_levelæ—¶è§¦å‘è¡¥è´§æé†’",
        "ç”¨æˆ·æ³¨å†Œ: registration_dateè®°å½•æ³¨å†Œæ—¶é—´ï¼Œlast_loginè®°å½•æœ€åç™»å½•æ—¶é—´"
    ]
    
    for rule in business_rules:
        content += f"â€¢ {rule}\n"
    
    return content


def create_enhanced_database_docs(db_config, output_dir):
    """åˆ›å»ºæ•°æ®åº“æ–‡æ¡£"""
    extractor = DatabaseKnowledgeExtractor(db_config, "D:/HuangJZh/Qwen/Qwen3-8B")
    extractor.connect()
    
    # æå–æ›´è¯¦ç»†çš„ä¿¡æ¯
    schema_info = extractor.extract_schema_info()
    sample_data = extractor.extract_sample_data(10)  # æ›´å¤šæ ·æœ¬
    
    docs = []
    
    # 1. æ•°æ®åº“æ¦‚è§ˆ
    overview = generate_enhanced_overview(schema_info, sample_data)
    docs.append(("enhanced_overview.txt", overview))
    
    # 2. è¯¦ç»†çš„è¡¨æ–‡æ¡£ï¼ˆåŒ…å«æ•°æ®ç±»å‹å’Œçº¦æŸï¼‰
    for table_name in schema_info["tables"]:
        table_doc = generate_detailed_table_doc(table_name, schema_info["tables"][table_name], sample_data.get(table_name, []))
        docs.append((f"table_{table_name}_detailed.txt", table_doc))
    
    # 3. æŸ¥è¯¢æ¨¡å¼æ–‡æ¡£
    query_patterns = generate_query_patterns()
    docs.append(("query_patterns.txt", query_patterns))
    
    # 4. ä¸šåŠ¡é€»è¾‘æ–‡æ¡£
    business_logic = generate_business_logic()
    docs.append(("business_logic.txt", business_logic))
    
    # ä¿å­˜æ–‡æ¡£
    os.makedirs(output_dir, exist_ok=True)
    for filename, content in docs:
        with open(os.path.join(output_dir, filename), "w", encoding="utf-8") as f:
            f.write(content)
    
    print(f"âœ… æ•°æ®åº“æ–‡æ¡£å·²ç”Ÿæˆåˆ° {output_dir}")


class Config:
    DOCUMENTS_DIR = "D:/HuangJZh/Qwen3/enhanced_database_docs"
    CHUNK_SIZE = 600
    CHUNK_OVERLAP = 80
    EMBEDDING_MODEL_NAME = "BAAI/bge-m3"  
    LLM_MODEL_NAME = "D:/HuangJZh/Qwen/Qwen3-8B"  
    VECTOR_DB_DIR = "vector_db_enhanced"
    TOP_K = 4


def main():
    # æ•°æ®åº“é…ç½®
    db_config = {
        'host': 'localhost',
        'user': 'root',
        'password': 'admin',
        'database': 'test_rag_mid'
    }
    
    config = Config()
    
    print("ğŸš€ å¼€å§‹RAGå¯¹æ¯”æµ‹è¯•")
    print("=" * 60)
    
    # ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ•°æ®åº“æ–‡æ¡£
    print("ğŸ“ ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºæ•°æ®åº“æ–‡æ¡£...")
    create_enhanced_database_docs(db_config, config.DOCUMENTS_DIR)
    
    # ç¬¬äºŒæ­¥ï¼šæ„å»ºRAGç³»ç»Ÿ
    print("\nğŸ”§ ç¬¬äºŒæ­¥ï¼šæ„å»ºRAGç³»ç»Ÿ...")
    rag_system = AdvancedRAGSystem(config, db_config)
    
    # å¤„ç†æ–‡æ¡£
    loader = DirectoryLoader(
        config.DOCUMENTS_DIR,
        glob="*.txt",
        loader_cls=TextLoader,
        loader_kwargs={"encoding": "utf-8"}
    )
    documents = loader.load()
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE,
        chunk_overlap=config.CHUNK_OVERLAP,
        separators=["\n\n", "\n", "ã€‚", "ï¼Œ", "ï¼›", "ã€", " ", ""]
    )
    texts = text_splitter.split_documents(documents)
    
    # åˆ›å»ºå‘é‡åº“
    rag_system.vector_db = Chroma.from_documents(
        documents=texts,
        embedding=rag_system.embeddings,
        persist_directory=config.VECTOR_DB_DIR
    )
    rag_system.vector_db.persist()
    
    # åŠ è½½RAGç³»ç»Ÿ
    rag_system.load_rag_system()
    
    # ç¬¬ä¸‰æ­¥ï¼šè¿è¡ŒæŒ‘æˆ˜æ€§æµ‹è¯•
    print("\nğŸ¯ ç¬¬ä¸‰æ­¥ï¼šè¿è¡ŒæŒ‘æˆ˜æ€§æµ‹è¯•åœºæ™¯...")
    comparison = EnhancedRAGComparison(db_config, config.LLM_MODEL_NAME)
    comparison.connect()
    
    test_scenarios = comparison.get_challenging_test_scenarios()
    results = []
    
    for scenario in test_scenarios:
        print(f"\n{'='*80}")
        print(f"æµ‹è¯•: {scenario['name']}")
        # print(f"æŒ‘æˆ˜: {scenario['challenge']}")
        print(f"é—®é¢˜: {scenario['question']}")
        
        # æ— RAGç”Ÿæˆ
        print("\n1. æ— RAGç”ŸæˆSQL...")
        sql_no_rag = rag_system.generate_sql_without_rag(scenario['question'])
        result_no_rag = comparison.execute_and_compare(
            sql_no_rag, scenario['expected_sql'], "æ— RAGç»“æœ"
        )
        
        # æœ‰RAGç”Ÿæˆ
        print("\n2. æœ‰RAGç”ŸæˆSQL...")
        sql_with_rag, source_docs = rag_system.generate_sql_with_rag(scenario['question'])
        result_with_rag = comparison.execute_and_compare(
            sql_with_rag, scenario['expected_sql'], "æœ‰RAGç»“æœ"
        )
        
        # # æ˜¾ç¤ºç›¸å…³æ–‡æ¡£
        # print(f"\nğŸ“š ç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
        # for i, doc in enumerate(source_docs[:2], 1):
        #     print(f"æ–‡æ¡£ {i}: {doc.page_content[:150]}...")
        

if __name__ == "__main__":
    os.environ["TOKENIZERS_PARALLELISM"] = "false"
    main()
```

### quert_test.py //æµ‹è¯•sqlè¯­å¥

```
import mysql.connector
import pandas as pd

def run_sql_query(sql_query, description="è‡ªå®šä¹‰æŸ¥è¯¢"):
    """
    æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶æ˜¾ç¤ºç»“æœ
    
    å‚æ•°:
        sql_query: SQLæŸ¥è¯¢è¯­å¥
        description: æŸ¥è¯¢æè¿°
    """
    # æ•°æ®åº“é…ç½®
    db_config = {
        'host': 'localhost',
        'user': 'root',
        'password': 'admin',
        'database': 'test_rag_mid'
    }
    
    print(f"\nğŸ¯ {description}")
    print("=" * 60)
    print(f"SQL: {sql_query}")
    print("-" * 60)
    
    try:
        # è¿æ¥æ•°æ®åº“
        conn = mysql.connector.connect(**db_config)
        cursor = conn.cursor(dictionary=True)
        
        # æ‰§è¡ŒæŸ¥è¯¢
        cursor.execute(sql_query)
        results = cursor.fetchall()
        
        if results:
            df = pd.DataFrame(results)
            print(f"âœ… è¿”å› {len(df)} è¡Œæ•°æ®")
            print("\nğŸ“Š ç»“æœ:")
            print(df.to_string(index=False))
        else:
            print("â„¹ï¸  æŸ¥è¯¢æˆåŠŸï¼Œä½†æœªè¿”å›æ•°æ®")
            
        # å…³é—­è¿æ¥
        cursor.close()
        conn.close()
        
    except Exception as e:
        print(f"âŒ æŸ¥è¯¢å¤±è´¥: {e}")


if __name__ == "__main__":
    print("test_rag_mid ç®€å•æŸ¥è¯¢å·¥å…·")
    
    run_sql_query("""

    """, "ç”¨æˆ·è®¢å•è¿æ¥æŸ¥è¯¢")
    
    
    print("\nğŸ’¡ æç¤º: è¯·ç¼–è¾‘æ­¤æ–‡ä»¶ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶ä¿®æ”¹ä¸Šé¢çš„æŸ¥è¯¢è¯­å¥æ¥æµ‹è¯•æ‚¨çš„SQLæŸ¥è¯¢")
```

