# 前端运行说明（中文）

## 先决条件

- Linux / macOS / Windows（以 bash 为示例命令）
- Python 3.8+（建议 3.10/3.11/3.12）

注意：模型依赖（如 `transformers`、`torch`、LLM/嵌入包）体积通常很大，安装并加载模型前请确保有足够磁盘与内存/GPU 显存。

## 安装最小依赖（用于运行前端与 API）

```bash
pip install fastapi uvicorn pydantic psutil
```

## 如何启动后端服务

首先激活虚拟环境。

```bash
cd rag_system
python app.py
```

启动后，在浏览器打开：

http://127.0.0.1:8000/

页面会显示“对话 / 测试”单页应用。

## 前端快速指南（页面交互说明）

页面被分为两个主要视图：对话（Chat）和测试（Tests），可通过右上角的“切换到测试模式”按钮切换。

**所有操作进行前，必须先初始化服务！**

对话（Chat）页面：
- 输入框：在左侧用于输入自然语言问题（`问题`）
- 模式选择（三选一，单选）：
  - 有RAG：基于向量检索 + LLM 生成 SQL
  - 无RAG：仅使用 LLM（模型知识）生成 SQL
  - 混合（Hybrid）：同时生成“有RAG”和“无RAG”两条 SQL，并尝试分别执行（若为 SELECT）
- 发送（发送按钮）：提交到 `/query`，结果显示在左侧 Result 区
- 历史（右侧列）：按时间倒序显示每条查询的记录，包含：时间、问题、SQL、查询是否成功、查询结果（成功）或错误信息（失败）。混合模式会同时展示两条 SQL 和两条执行结果。

测试（Tests）页面：
- 运行对比测试：会在后台启动一组预定义的对比场景，前端轮询 `/run_tests_progress` 并把每个测试的“问题／有RAG生成结果／无RAG生成结果”逐条展示。
- 运行期间按钮会变为“终止”，可发送 `/run_tests_stop` 请求进行协作式终止（注意：目前中断点为测试之间的边界，无法保证在单次生成中立刻中断）。

其他控件：
- 初始化系统（`初始化系统`）：触发 `/init`，会（可选）加载共享 LLM、准备对话/测试系统（耗时且可能占用显存）。
- 预加载嵌入模型：调用 `/load_embeddings` 以便复用嵌入模型（减小重复加载）。
- 系统状态：页面顶部展示 CPU、内存、GPU 可用性与简要信息（通过 `/status` 获取）。

